(dcdc-py3) yxchen2@gpu-comp-101:~/NNM$ python scan.py --config_env configs/env.yml --config_exp configs/scan/scan_cifar10.yml --gpus 0 
{'setup': 'scan', 'criterion': 'scan', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 3, 'backbone': 'resnet18', 'train_db_name': 'cifar-10', 'val_db_name': 'cifar-10', 'num_classes': 10, 'num_neighbors': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'epochs': 20, 'batch_size': 400, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': './results/cifar-10/pretext', 'pretext_checkpoint': './results/cifar-10/pretext/checkpoint.pth.tar', 'pretext_model': './results/cifar-10/pretext/model.pth.tar', 'topk_neighbors_train_path': './results/cifar-10/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': './results/cifar-10/pretext/topk-val-neighbors.npy', 'scan_dir': './results/cifar-10/scan', 'scan_checkpoint': './results/cifar-10/scan/checkpoint.pth.tar', 'scan_model': './results/cifar-10/scan/model.pth.tar', 'selflabel_dir': './results/cifar-10/selflabel', 'selflabel_checkpoint': './results/cifar-10/selflabel/checkpoint.pth.tar', 'selflabel_model': './results/cifar-10/selflabel/model.pth.tar'}
Get dataset and dataloaders
Files already downloaded and verified
Files already downloaded and verified
Train transforms: Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=None)
    <data.augment.Augment object at 0x14996135d350>
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
    <data.augment.Cutout object at 0x14996135d210>
)
Validation transforms: Compose(
    CenterCrop(size=(32, 32))
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
Train samples 50000 - Val samples 10000
Get model
Data parallel will be used for acceleration purpose
Get optimizer
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001
)
Get loss
SCANLoss(
  (softmax): Softmax(dim=1)
  (bce): BCELoss()
  (ce): CrossEntropyLoss()
  (confidence_ce): ConfidenceBasedCE(
    (loss): MaskedCrossEntropyLoss()
    (softmax): Softmax(dim=1)
  )
)
No checkpoint file at ./results/cifar-10/scan/checkpoint.pth.tar
Starting main loop
Epoch 1/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [0][  0/125]     Total Loss -6.9066e+00 (-6.9066e+00)    Consistency Loss 2.3009e+00 (2.3009e+00)        Class Cross Entropy 2.3021e+00 (2.3021e+00)    Entropy 2.3019e+00 (2.3019e+00)
Epoch: [0][ 25/125]     Total Loss -7.0014e+00 (-6.9428e+00)    Consistency Loss 2.2513e+00 (2.2852e+00)        Class Cross Entropy 2.2530e+00 (2.2830e+00)    Entropy 2.3011e+00 (2.3022e+00)
Epoch: [0][ 50/125]     Total Loss -7.1815e+00 (-7.0163e+00)    Consistency Loss 2.1365e+00 (2.2422e+00)        Class Cross Entropy 2.1574e+00 (2.2441e+00)    Entropy 2.2951e+00 (2.3005e+00)
Epoch: [0][ 75/125]     Total Loss -7.3125e+00 (-7.0944e+00)    Consistency Loss 2.0279e+00 (2.1868e+00)        Class Cross Entropy 2.1025e+00 (2.2061e+00)    Entropy 2.2886e+00 (2.2975e+00)
Epoch: [0][100/125]     Total Loss -7.4986e+00 (-7.1740e+00)    Consistency Loss 1.9025e+00 (2.1287e+00)        Class Cross Entropy 2.0353e+00 (2.1712e+00)    Entropy 2.2873e+00 (2.2948e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.16396117210388184
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.29054856300354, 'consistency': 1.6562778949737549, 'ce': 1.904801607131958, 'total_loss': 1.2705309391021729}, {'entropy': 2.2933952808380127, 'consistency': 1.6914178133010864, 'ce': 1.8875783681869507, 'total_loss': 1.2856009006500244}, {'entropy': 2.2940471172332764, 'consistency': 1.6921969652175903, 'ce': 1.880128264427185, 'total_loss': 1.278278112411499}], 'lowest_loss_head': 0, 'lowest_loss': 1.2705309391021729}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.5241, 'ARI': 0.3545599420496837, 'NMI': 0.4706171505673458, 'ACC Top-5': 0.8216, 'hungarian_match': [(0, 4), (1, 8), (2, 5), (3, 3), (4, 0), (5, 7), (6, 1), (7, 2), (8, 9), (9, 6)]}
New lowest loss on validation set: 10000.0000 -> 1.2705
Best ACC on validation set: 0.0000 -> 0.5241
Lowest loss head is 0
Checkpoint ...
Epoch 2/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [1][  0/125]     Total Loss -3.0217e+00 (-3.0217e+00)    Consistency Loss 1.7710e+00 (1.7710e+00)        Class Cross Entropy 1.9724e+00 (1.9724e+00)    Entropy 2.2885e+00 (2.2885e+00)
Epoch: [1][ 25/125]     Total Loss -3.1368e+00 (-3.0320e+00)    Consistency Loss 1.7099e+00 (1.7489e+00)        Class Cross Entropy 1.9228e+00 (1.9557e+00)    Entropy 2.2946e+00 (2.2924e+00)
Epoch: [1][ 50/125]     Total Loss -3.3059e+00 (-3.1069e+00)    Consistency Loss 1.5694e+00 (1.6985e+00)        Class Cross Entropy 1.8722e+00 (1.9307e+00)    Entropy 2.2948e+00 (2.2937e+00)
Epoch: [1][ 75/125]     Total Loss -3.3741e+00 (-3.1846e+00)    Consistency Loss 1.4880e+00 (1.6437e+00)        Class Cross Entropy 1.8419e+00 (1.9056e+00)    Entropy 2.2959e+00 (2.2945e+00)
Epoch: [1][100/125]     Total Loss -3.5567e+00 (-3.2548e+00)    Consistency Loss 1.3362e+00 (1.5855e+00)        Class Cross Entropy 1.7808e+00 (1.8819e+00)    Entropy 2.2970e+00 (2.2949e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1575183868408203
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.2962567806243896, 'consistency': 1.0121880769729614, 'ce': 1.6248300075531006, 'total_loss': 0.34076130390167236}, {'entropy': 2.2954206466674805, 'consistency': 0.9714593291282654, 'ce': 1.593102216720581, 'total_loss': 0.26914089918136597}, {'entropy': 2.2838501930236816, 'consistency': 0.9775495529174805, 'ce': 1.6032474040985107, 'total_loss': 0.29694676399230957}], 'lowest_loss_head': 1, 'lowest_loss': 0.26914089918136597}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.6292, 'ARI': 0.4279963035194742, 'NMI': 0.5417720652649446, 'ACC Top-5': 0.9549, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
New lowest loss on validation set: 1.2705 -> 0.2691
Best ACC on validation set: 0.5241 -> 0.6292
Lowest loss head is 1
Checkpoint ...
Epoch 3/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [2][  0/125]     Total Loss -3.3195e+00 (-3.3195e+00)    Consistency Loss 1.2629e+00 (1.2629e+00)        Class Cross Entropy 1.7664e+00 (1.7664e+00)    Entropy 2.2982e+00 (2.2982e+00)
Epoch: [2][ 25/125]     Total Loss -3.4221e+00 (-3.4353e+00)    Consistency Loss 1.2369e+00 (1.2607e+00)        Class Cross Entropy 1.7394e+00 (1.7489e+00)    Entropy 2.3012e+00 (2.2998e+00)
Epoch: [2][ 50/125]     Total Loss -3.4066e+00 (-3.4668e+00)    Consistency Loss 1.1998e+00 (1.2404e+00)        Class Cross Entropy 1.7306e+00 (1.7403e+00)    Entropy 2.2998e+00 (2.3000e+00)
Epoch: [2][ 75/125]     Total Loss -3.5554e+00 (-3.5035e+00)    Consistency Loss 1.1001e+00 (1.2092e+00)        Class Cross Entropy 1.7021e+00 (1.7305e+00)    Entropy 2.3001e+00 (2.3001e+00)
Epoch: [2][100/125]     Total Loss -3.6941e+00 (-3.5299e+00)    Consistency Loss 1.1044e+00 (1.1844e+00)        Class Cross Entropy 1.6903e+00 (1.7230e+00)    Entropy 2.2994e+00 (2.3001e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15311431884765625
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.2965574264526367, 'consistency': 0.7444656491279602, 'ce': 1.5248743295669556, 'total_loss': -0.027217447757720947}, {'entropy': 2.297193765640259, 'consistency': 0.7548322677612305, 'ce': 1.5259171724319458, 'total_loss': -0.01644432544708252}, {'entropy': 2.2934718132019043, 'consistency': 0.7788029909133911, 'ce': 1.5423250198364258, 'total_loss': 0.027656197547912598}], 'lowest_loss_head': 0, 'lowest_loss': -0.027217447757720947}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.7077, 'ARI': 0.5152957579020366, 'NMI': 0.6058557236718037, 'ACC Top-5': 0.96, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: 0.2691 -> -0.0272
Best ACC on validation set: 0.6292 -> 0.7077
Lowest loss head is 0
Checkpoint ...
Epoch 4/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [3][  0/125]     Total Loss -3.6200e+00 (-3.6200e+00)    Consistency Loss 9.9096e-01 (9.9096e-01)        Class Cross Entropy 1.6680e+00 (1.6680e+00)    Entropy 2.3001e+00 (2.3001e+00)
Epoch: [3][ 25/125]     Total Loss -3.7455e+00 (-3.6494e+00)    Consistency Loss 9.9506e-01 (1.0156e+00)        Class Cross Entropy 1.6697e+00 (1.6779e+00)    Entropy 2.3013e+00 (2.3008e+00)
Epoch: [3][ 50/125]     Total Loss -3.7419e+00 (-3.6444e+00)    Consistency Loss 9.9698e-01 (1.0143e+00)        Class Cross Entropy 1.6669e+00 (1.6764e+00)    Entropy 2.3007e+00 (2.3009e+00)
Epoch: [3][ 75/125]     Total Loss -3.8509e+00 (-3.6574e+00)    Consistency Loss 9.8843e-01 (1.0076e+00)        Class Cross Entropy 1.6698e+00 (1.6742e+00)    Entropy 2.2997e+00 (2.3008e+00)
Epoch: [3][100/125]     Total Loss -3.6977e+00 (-3.6702e+00)    Consistency Loss 9.3597e-01 (9.9540e-01)        Class Cross Entropy 1.6516e+00 (1.6708e+00)    Entropy 2.3004e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15851497650146484
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.29998779296875, 'consistency': 0.6919729113578796, 'ce': 1.515803575515747, 'total_loss': -0.09221130609512329}, {'entropy': 2.3000054359436035, 'consistency': 0.691396951675415, 'ce': 1.515533685684204, 'total_loss': -0.09307479858398438}, {'entropy': 2.300123691558838, 'consistency': 0.6945058107376099, 'ce': 1.5162990093231201, 'total_loss': -0.08931887149810791}], 'lowest_loss_head': 1, 'lowest_loss': -0.09307479858398438}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.7664, 'ARI': 0.5842207551569593, 'NMI': 0.6466614875356008, 'ACC Top-5': 0.9809, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
New lowest loss on validation set: -0.0272 -> -0.0931
Best ACC on validation set: 0.7077 -> 0.7664
Lowest loss head is 1
Checkpoint ...
Epoch 5/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [4][  0/125]     Total Loss -3.7180e+00 (-3.7180e+00)    Consistency Loss 9.7306e-01 (9.7306e-01)        Class Cross Entropy 1.6674e+00 (1.6674e+00)    Entropy 2.3007e+00 (2.3007e+00)
Epoch: [4][ 25/125]     Total Loss -3.7645e+00 (-3.6900e+00)    Consistency Loss 9.5441e-01 (9.5930e-01)        Class Cross Entropy 1.6637e+00 (1.6641e+00)    Entropy 2.3009e+00 (2.3009e+00)
Epoch: [4][ 50/125]     Total Loss -3.7308e+00 (-3.7001e+00)    Consistency Loss 8.9453e-01 (9.4572e-01)        Class Cross Entropy 1.6420e+00 (1.6601e+00)    Entropy 2.3004e+00 (2.3009e+00)
Epoch: [4][ 75/125]     Total Loss -3.7201e+00 (-3.7075e+00)    Consistency Loss 9.1743e-01 (9.4203e-01)        Class Cross Entropy 1.6529e+00 (1.6587e+00)    Entropy 2.3005e+00 (2.3009e+00)
Epoch: [4][100/125]     Total Loss -3.7156e+00 (-3.7153e+00)    Consistency Loss 8.8168e-01 (9.3155e-01)        Class Cross Entropy 1.6434e+00 (1.6563e+00)    Entropy 2.2970e+00 (2.3008e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15740561485290527
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3001651763916016, 'consistency': 0.6664440035820007, 'ce': 1.5123693943023682, 'total_loss': -0.12135177850723267}, {'entropy': 2.300006151199341, 'consistency': 0.6642791628837585, 'ce': 1.5120832920074463, 'total_loss': -0.12364369630813599}, {'entropy': 2.2998170852661133, 'consistency': 0.6735939383506775, 'ce': 1.5133097171783447, 'total_loss': -0.11291342973709106}], 'lowest_loss_head': 1, 'lowest_loss': -0.12364369630813599}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.7639, 'ARI': 0.5817851218628829, 'NMI': 0.6574704256284821, 'ACC Top-5': 0.9743, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.0931 -> -0.1236
Lowest loss head is 1
Checkpoint ...
Epoch 6/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [5][  0/125]     Total Loss -3.8141e+00 (-3.8141e+00)    Consistency Loss 9.2144e-01 (9.2144e-01)        Class Cross Entropy 1.6541e+00 (1.6541e+00)    Entropy 2.2998e+00 (2.2998e+00)
Epoch: [5][ 25/125]     Total Loss -3.7511e+00 (-3.7567e+00)    Consistency Loss 8.7172e-01 (8.9071e-01)        Class Cross Entropy 1.6396e+00 (1.6458e+00)    Entropy 2.3003e+00 (2.3004e+00)
Epoch: [5][ 50/125]     Total Loss -3.6928e+00 (-3.7542e+00)    Consistency Loss 8.8604e-01 (8.9359e-01)        Class Cross Entropy 1.6409e+00 (1.6464e+00)    Entropy 2.3011e+00 (2.3005e+00)
Epoch: [5][ 75/125]     Total Loss -3.7183e+00 (-3.7556e+00)    Consistency Loss 9.1729e-01 (8.9125e-01)        Class Cross Entropy 1.6579e+00 (1.6462e+00)    Entropy 2.3003e+00 (2.3005e+00)
Epoch: [5][100/125]     Total Loss -3.6903e+00 (-3.7562e+00)    Consistency Loss 9.0966e-01 (8.8979e-01)        Class Cross Entropy 1.6542e+00 (1.6459e+00)    Entropy 2.3000e+00 (2.3005e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1543722152709961
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.2992942333221436, 'consistency': 0.6586254835128784, 'ce': 1.5129351615905762, 'total_loss': -0.12773358821868896}, {'entropy': 2.299147367477417, 'consistency': 0.657306432723999, 'ce': 1.512636661529541, 'total_loss': -0.12920427322387695}, {'entropy': 2.298860788345337, 'consistency': 0.6578075885772705, 'ce': 1.5126689672470093, 'total_loss': -0.12838423252105713}], 'lowest_loss_head': 1, 'lowest_loss': -0.12920427322387695}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.7756, 'ARI': 0.5990402670075082, 'NMI': 0.6649932448091334, 'ACC Top-5': 0.976, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
New lowest loss on validation set: -0.0931 -> -0.1292
Best ACC on validation set: 0.7664 -> 0.7756
Lowest loss head is 1
Checkpoint ...
Epoch 7/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [6][  0/125]     Total Loss -3.7715e+00 (-3.7715e+00)    Consistency Loss 8.3442e-01 (8.3442e-01)        Class Cross Entropy 1.6238e+00 (1.6238e+00)    Entropy 2.3020e+00 (2.3020e+00)
Epoch: [6][ 25/125]     Total Loss -3.7892e+00 (-3.7686e+00)    Consistency Loss 8.3964e-01 (8.5597e-01)        Class Cross Entropy 1.6340e+00 (1.6377e+00)    Entropy 2.3005e+00 (2.3005e+00)
Epoch: [6][ 50/125]     Total Loss -3.7926e+00 (-3.7758e+00)    Consistency Loss 8.3800e-01 (8.5797e-01)        Class Cross Entropy 1.6361e+00 (1.6387e+00)    Entropy 2.2989e+00 (2.3005e+00)
Epoch: [6][ 75/125]     Total Loss -3.8252e+00 (-3.7681e+00)    Consistency Loss 8.7483e-01 (8.6135e-01)        Class Cross Entropy 1.6415e+00 (1.6390e+00)    Entropy 2.3005e+00 (2.3005e+00)
Epoch: [6][100/125]     Total Loss -3.7302e+00 (-3.7684e+00)    Consistency Loss 8.5895e-01 (8.5839e-01)        Class Cross Entropy 1.6366e+00 (1.6383e+00)    Entropy 2.3012e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1581275463104248
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301591396331787, 'consistency': 0.6466682553291321, 'ce': 1.5114176273345947, 'total_loss': -0.1435055136680603}, {'entropy': 2.301649570465088, 'consistency': 0.6459923386573792, 'ce': 1.5113927125930786, 'total_loss': -0.14426451921463013}, {'entropy': 2.301522731781006, 'consistency': 0.6465592384338379, 'ce': 1.5114085674285889, 'total_loss': -0.1435549259185791}], 'lowest_loss_head': 1, 'lowest_loss': -0.14426451921463013}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.7829, 'ARI': 0.6103815504465966, 'NMI': 0.6721951923128366, 'ACC Top-5': 0.9672, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
New lowest loss on validation set: -0.1292 -> -0.1443
Best ACC on validation set: 0.7756 -> 0.7829
Lowest loss head is 1
Checkpoint ...
Epoch 8/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [7][  0/125]     Total Loss -3.7927e+00 (-3.7927e+00)    Consistency Loss 8.7165e-01 (8.7165e-01)        Class Cross Entropy 1.6357e+00 (1.6357e+00)    Entropy 2.3011e+00 (2.3011e+00)
Epoch: [7][ 25/125]     Total Loss -3.8662e+00 (-3.7869e+00)    Consistency Loss 8.0185e-01 (8.4713e-01)        Class Cross Entropy 1.6276e+00 (1.6350e+00)    Entropy 2.3018e+00 (2.3011e+00)
Epoch: [7][ 50/125]     Total Loss -3.8085e+00 (-3.7969e+00)    Consistency Loss 8.1218e-01 (8.4288e-01)        Class Cross Entropy 1.6260e+00 (1.6337e+00)    Entropy 2.3004e+00 (2.3009e+00)
Epoch: [7][ 75/125]     Total Loss -3.7526e+00 (-3.7943e+00)    Consistency Loss 8.7578e-01 (8.4322e-01)        Class Cross Entropy 1.6393e+00 (1.6339e+00)    Entropy 2.3009e+00 (2.3009e+00)
Epoch: [7][100/125]     Total Loss -3.7527e+00 (-3.7915e+00)    Consistency Loss 8.2768e-01 (8.4318e-01)        Class Cross Entropy 1.6304e+00 (1.6339e+00)    Entropy 2.3004e+00 (2.3008e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15557074546813965
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.299872875213623, 'consistency': 0.6404197812080383, 'ce': 1.5113481283187866, 'total_loss': -0.1481049656867981}, {'entropy': 2.299960136413574, 'consistency': 0.6413888931274414, 'ce': 1.511386513710022, 'total_loss': -0.14718472957611084}, {'entropy': 2.2998883724212646, 'consistency': 0.6440322995185852, 'ce': 1.5118542909622192, 'total_loss': -0.1440017819404602}], 'lowest_loss_head': 0, 'lowest_loss': -0.1481049656867981}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.7884, 'ARI': 0.6181170886223527, 'NMI': 0.680991469947722, 'ACC Top-5': 0.9714, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: -0.1443 -> -0.1481
Best ACC on validation set: 0.7829 -> 0.7884
Lowest loss head is 0
Checkpoint ...
Epoch 9/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [8][  0/125]     Total Loss -3.7187e+00 (-3.7187e+00)    Consistency Loss 8.5821e-01 (8.5821e-01)        Class Cross Entropy 1.6384e+00 (1.6384e+00)    Entropy 2.3021e+00 (2.3021e+00)
Epoch: [8][ 25/125]     Total Loss -3.7380e+00 (-3.7714e+00)    Consistency Loss 8.2119e-01 (8.4430e-01)        Class Cross Entropy 1.6281e+00 (1.6338e+00)    Entropy 2.3003e+00 (2.3011e+00)
Epoch: [8][ 50/125]     Total Loss -3.7537e+00 (-3.7787e+00)    Consistency Loss 8.7924e-01 (8.4211e-01)        Class Cross Entropy 1.6420e+00 (1.6327e+00)    Entropy 2.3019e+00 (2.3010e+00)
Epoch: [8][ 75/125]     Total Loss -3.6797e+00 (-3.7935e+00)    Consistency Loss 8.6875e-01 (8.3467e-01)        Class Cross Entropy 1.6453e+00 (1.6313e+00)    Entropy 2.3014e+00 (2.3011e+00)
Epoch: [8][100/125]     Total Loss -3.7332e+00 (-3.7981e+00)    Consistency Loss 8.4618e-01 (8.3153e-01)        Class Cross Entropy 1.6377e+00 (1.6304e+00)    Entropy 2.3000e+00 (2.3011e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.2152543067932129
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.2990145683288574, 'consistency': 0.6291792988777161, 'ce': 1.5099356174468994, 'total_loss': -0.15989965200424194}, {'entropy': 2.2990782260894775, 'consistency': 0.6274448037147522, 'ce': 1.5097681283950806, 'total_loss': -0.16186529397964478}, {'entropy': 2.2989234924316406, 'consistency': 0.6263168454170227, 'ce': 1.5095701217651367, 'total_loss': -0.1630365252494812}], 'lowest_loss_head': 2, 'lowest_loss': -0.1630365252494812}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.7967, 'ARI': 0.6299335761126411, 'NMI': 0.6907124563251539, 'ACC Top-5': 0.9651, 'hungarian_match': [(0, 2), (1, 8), (2, 5), (3, 9), (4, 7), (5, 4), (6, 1), (7, 3), (8, 0), (9, 6)]}
New lowest loss on validation set: -0.1481 -> -0.1630
Best ACC on validation set: 0.7884 -> 0.7967
Lowest loss head is 2
Checkpoint ...
Epoch 10/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [9][  0/125]     Total Loss -3.6883e+00 (-3.6883e+00)    Consistency Loss 8.8481e-01 (8.8481e-01)        Class Cross Entropy 1.6400e+00 (1.6400e+00)    Entropy 2.3011e+00 (2.3011e+00)
Epoch: [9][ 25/125]     Total Loss -3.8076e+00 (-3.8064e+00)    Consistency Loss 7.8401e-01 (8.1589e-01)        Class Cross Entropy 1.6192e+00 (1.6259e+00)    Entropy 2.3009e+00 (2.3009e+00)
Epoch: [9][ 50/125]     Total Loss -3.8138e+00 (-3.7970e+00)    Consistency Loss 8.0686e-01 (8.1670e-01)        Class Cross Entropy 1.6267e+00 (1.6262e+00)    Entropy 2.3005e+00 (2.3008e+00)
Epoch: [9][ 75/125]     Total Loss -3.8337e+00 (-3.7931e+00)    Consistency Loss 8.0382e-01 (8.1717e-01)        Class Cross Entropy 1.6254e+00 (1.6265e+00)    Entropy 2.3000e+00 (2.3007e+00)
Epoch: [9][100/125]     Total Loss -3.7938e+00 (-3.7906e+00)    Consistency Loss 8.4161e-01 (8.2137e-01)        Class Cross Entropy 1.6321e+00 (1.6271e+00)    Entropy 2.2999e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15482854843139648
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301365613937378, 'consistency': 0.6274372935295105, 'ce': 1.510203242301941, 'total_loss': -0.1637250781059265}, {'entropy': 2.301363945007324, 'consistency': 0.6275523900985718, 'ce': 1.5103042125701904, 'total_loss': -0.163507342338562}, {'entropy': 2.301210641860962, 'consistency': 0.6304126977920532, 'ce': 1.5107499361038208, 'total_loss': -0.1600480079650879}], 'lowest_loss_head': 0, 'lowest_loss': -0.1637250781059265}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8091, 'ARI': 0.6472147824043816, 'NMI': 0.6995186755856625, 'ACC Top-5': 0.9676, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: -0.1630 -> -0.1637
Best ACC on validation set: 0.7967 -> 0.8091
Lowest loss head is 0
Checkpoint ...
Epoch 11/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [10][  0/125]    Total Loss -3.7458e+00 (-3.7458e+00)    Consistency Loss 8.5930e-01 (8.5930e-01)        Class Cross Entropy 1.6289e+00 (1.6289e+00)    Entropy 2.2994e+00 (2.2994e+00)
Epoch: [10][ 25/125]    Total Loss -3.8961e+00 (-3.7910e+00)    Consistency Loss 8.3044e-01 (8.1480e-01)        Class Cross Entropy 1.6382e+00 (1.6253e+00)    Entropy 2.2997e+00 (2.3006e+00)
Epoch: [10][ 50/125]    Total Loss -3.8205e+00 (-3.8067e+00)    Consistency Loss 7.9415e-01 (8.0716e-01)        Class Cross Entropy 1.6209e+00 (1.6230e+00)    Entropy 2.3015e+00 (2.3007e+00)
Epoch: [10][ 75/125]    Total Loss -3.7912e+00 (-3.8020e+00)    Consistency Loss 8.0480e-01 (8.1077e-01)        Class Cross Entropy 1.6206e+00 (1.6234e+00)    Entropy 2.3016e+00 (2.3006e+00)
Epoch: [10][100/125]    Total Loss -3.8402e+00 (-3.8066e+00)    Consistency Loss 7.5825e-01 (8.0538e-01)        Class Cross Entropy 1.6097e+00 (1.6220e+00)    Entropy 2.3012e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.22772908210754395
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301096200942993, 'consistency': 0.6168090105056763, 'ce': 1.5087478160858154, 'total_loss': -0.17553937435150146}, {'entropy': 2.3011205196380615, 'consistency': 0.6152805089950562, 'ce': 1.5085378885269165, 'total_loss': -0.17730212211608887}, {'entropy': 2.3009226322174072, 'consistency': 0.6125473380088806, 'ce': 1.508189082145691, 'total_loss': -0.1801862120628357}], 'lowest_loss_head': 2, 'lowest_loss': -0.1801862120628357}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8124, 'ARI': 0.654538711089446, 'NMI': 0.7037622523150703, 'ACC Top-5': 0.973, 'hungarian_match': [(0, 2), (1, 8), (2, 5), (3, 9), (4, 7), (5, 4), (6, 1), (7, 3), (8, 0), (9, 6)]}
New lowest loss on validation set: -0.1637 -> -0.1802
Best ACC on validation set: 0.8091 -> 0.8124
Lowest loss head is 2
Checkpoint ...
Epoch 12/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [11][  0/125]    Total Loss -3.7870e+00 (-3.7870e+00)    Consistency Loss 7.5048e-01 (7.5048e-01)        Class Cross Entropy 1.6095e+00 (1.6095e+00)    Entropy 2.3014e+00 (2.3014e+00)
Epoch: [11][ 25/125]    Total Loss -3.8530e+00 (-3.7937e+00)    Consistency Loss 8.1776e-01 (8.1838e-01)        Class Cross Entropy 1.6219e+00 (1.6254e+00)    Entropy 2.3019e+00 (2.3008e+00)
Epoch: [11][ 50/125]    Total Loss -3.7740e+00 (-3.8061e+00)    Consistency Loss 7.9336e-01 (8.0733e-01)        Class Cross Entropy 1.6173e+00 (1.6219e+00)    Entropy 2.3017e+00 (2.3009e+00)
Epoch: [11][ 75/125]    Total Loss -3.9119e+00 (-3.8112e+00)    Consistency Loss 7.6668e-01 (8.0743e-01)        Class Cross Entropy 1.6070e+00 (1.6219e+00)    Entropy 2.3020e+00 (2.3009e+00)
Epoch: [11][100/125]    Total Loss -3.8782e+00 (-3.8185e+00)    Consistency Loss 7.6452e-01 (8.0523e-01)        Class Cross Entropy 1.6062e+00 (1.6215e+00)    Entropy 2.2982e+00 (2.3008e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1580333709716797
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3014960289001465, 'consistency': 0.6286336779594421, 'ce': 1.5104711055755615, 'total_loss': -0.16239124536514282}, {'entropy': 2.3015096187591553, 'consistency': 0.6290689706802368, 'ce': 1.5106110572814941, 'total_loss': -0.16182959079742432}, {'entropy': 2.3014941215515137, 'consistency': 0.6306041479110718, 'ce': 1.5108469724655151, 'total_loss': -0.16004300117492676}], 'lowest_loss_head': 0, 'lowest_loss': -0.16239124536514282}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8142, 'ARI': 0.6561402591381231, 'NMI': 0.7077070594042705, 'ACC Top-5': 0.9725, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: -0.1802 -> -0.1624
Best ACC on validation set: 0.8124 -> 0.8142
Lowest loss head is 0
Checkpoint ...
Epoch 13/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [12][  0/125]    Total Loss -3.7776e+00 (-3.7776e+00)    Consistency Loss 8.0235e-01 (8.0235e-01)        Class Cross Entropy 1.6250e+00 (1.6250e+00)    Entropy 2.3014e+00 (2.3014e+00)
Epoch: [12][ 25/125]    Total Loss -3.8195e+00 (-3.8230e+00)    Consistency Loss 7.6878e-01 (7.9888e-01)        Class Cross Entropy 1.6101e+00 (1.6200e+00)    Entropy 2.2993e+00 (2.3009e+00)
Epoch: [12][ 50/125]    Total Loss -3.8619e+00 (-3.8318e+00)    Consistency Loss 7.3490e-01 (7.8373e-01)        Class Cross Entropy 1.6109e+00 (1.6161e+00)    Entropy 2.3004e+00 (2.3009e+00)
Epoch: [12][ 75/125]    Total Loss -3.7764e+00 (-3.8276e+00)    Consistency Loss 7.8257e-01 (7.8858e-01)        Class Cross Entropy 1.6212e+00 (1.6172e+00)    Entropy 2.3019e+00 (2.3009e+00)
Epoch: [12][100/125]    Total Loss -3.8646e+00 (-3.8294e+00)    Consistency Loss 7.7395e-01 (7.8885e-01)        Class Cross Entropy 1.6156e+00 (1.6175e+00)    Entropy 2.3020e+00 (2.3008e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15822148323059082
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301225423812866, 'consistency': 0.6095181107521057, 'ce': 1.5079591274261475, 'total_loss': -0.18374818563461304}, {'entropy': 2.30132794380188, 'consistency': 0.6085717082023621, 'ce': 1.5079067945480347, 'total_loss': -0.18484944105148315}, {'entropy': 2.301184892654419, 'consistency': 0.6091421842575073, 'ce': 1.5079774856567383, 'total_loss': -0.18406522274017334}], 'lowest_loss_head': 1, 'lowest_loss': -0.18484944105148315}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8185, 'ARI': 0.663686907917187, 'NMI': 0.7115405285972063, 'ACC Top-5': 0.9748, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
New lowest loss on validation set: -0.1624 -> -0.1848
Best ACC on validation set: 0.8142 -> 0.8185
Lowest loss head is 1
Checkpoint ...
Epoch 14/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [13][  0/125]    Total Loss -3.7361e+00 (-3.7361e+00)    Consistency Loss 8.7405e-01 (8.7405e-01)        Class Cross Entropy 1.6388e+00 (1.6388e+00)    Entropy 2.2980e+00 (2.2980e+00)
Epoch: [13][ 25/125]    Total Loss -3.7285e+00 (-3.8159e+00)    Consistency Loss 7.6932e-01 (7.8472e-01)        Class Cross Entropy 1.6081e+00 (1.6157e+00)    Entropy 2.3000e+00 (2.3005e+00)
Epoch: [13][ 50/125]    Total Loss -3.7390e+00 (-3.8172e+00)    Consistency Loss 8.4159e-01 (7.8631e-01)        Class Cross Entropy 1.6323e+00 (1.6161e+00)    Entropy 2.3011e+00 (2.3007e+00)
Epoch: [13][ 75/125]    Total Loss -3.8033e+00 (-3.8206e+00)    Consistency Loss 7.6210e-01 (7.8805e-01)        Class Cross Entropy 1.6064e+00 (1.6165e+00)    Entropy 2.3008e+00 (2.3008e+00)
Epoch: [13][100/125]    Total Loss -3.8878e+00 (-3.8132e+00)    Consistency Loss 7.7282e-01 (7.9475e-01)        Class Cross Entropy 1.6113e+00 (1.6179e+00)    Entropy 2.3006e+00 (2.3008e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15613603591918945
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301103115081787, 'consistency': 0.6200242042541504, 'ce': 1.5098531246185303, 'total_loss': -0.17122578620910645}, {'entropy': 2.3011531829833984, 'consistency': 0.6201325058937073, 'ce': 1.5098825693130493, 'total_loss': -0.17113810777664185}, {'entropy': 2.3010833263397217, 'consistency': 0.6208980083465576, 'ce': 1.5100499391555786, 'total_loss': -0.17013537883758545}], 'lowest_loss_head': 0, 'lowest_loss': -0.17122578620910645}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.818, 'ARI': 0.6637679850875412, 'NMI': 0.7093185259744503, 'ACC Top-5': 0.9724, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.1848 -> -0.1712
Lowest loss head is 1
Checkpoint ...
Epoch 15/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [14][  0/125]    Total Loss -3.9608e+00 (-3.9608e+00)    Consistency Loss 7.7431e-01 (7.7431e-01)        Class Cross Entropy 1.6138e+00 (1.6138e+00)    Entropy 2.3001e+00 (2.3001e+00)
Epoch: [14][ 25/125]    Total Loss -3.8966e+00 (-3.8569e+00)    Consistency Loss 7.8192e-01 (7.7202e-01)        Class Cross Entropy 1.6222e+00 (1.6133e+00)    Entropy 2.3012e+00 (2.3007e+00)
Epoch: [14][ 50/125]    Total Loss -3.8256e+00 (-3.8449e+00)    Consistency Loss 7.6640e-01 (7.7635e-01)        Class Cross Entropy 1.6071e+00 (1.6146e+00)    Entropy 2.2991e+00 (2.3007e+00)
Epoch: [14][ 75/125]    Total Loss -3.7996e+00 (-3.8432e+00)    Consistency Loss 7.8222e-01 (7.7630e-01)        Class Cross Entropy 1.6140e+00 (1.6139e+00)    Entropy 2.2999e+00 (2.3007e+00)
Epoch: [14][100/125]    Total Loss -3.7943e+00 (-3.8412e+00)    Consistency Loss 8.0996e-01 (7.7612e-01)        Class Cross Entropy 1.6178e+00 (1.6139e+00)    Entropy 2.3002e+00 (2.3008e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15642642974853516
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3018054962158203, 'consistency': 0.602871298789978, 'ce': 1.5077173709869385, 'total_loss': -0.1912168264389038}, {'entropy': 2.3018412590026855, 'consistency': 0.6010686159133911, 'ce': 1.5074937343597412, 'total_loss': -0.19327890872955322}, {'entropy': 2.3018245697021484, 'consistency': 0.6020036339759827, 'ce': 1.5076297521591187, 'total_loss': -0.19219118356704712}], 'lowest_loss_head': 1, 'lowest_loss': -0.19327890872955322}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8238, 'ARI': 0.670162132256719, 'NMI': 0.7156240845452004, 'ACC Top-5': 0.9781, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
New lowest loss on validation set: -0.1848 -> -0.1933
Best ACC on validation set: 0.8185 -> 0.8238
Lowest loss head is 1
Checkpoint ...
Epoch 16/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [15][  0/125]    Total Loss -3.7930e+00 (-3.7930e+00)    Consistency Loss 7.5146e-01 (7.5146e-01)        Class Cross Entropy 1.6057e+00 (1.6057e+00)    Entropy 2.3015e+00 (2.3015e+00)
Epoch: [15][ 25/125]    Total Loss -3.8202e+00 (-3.8344e+00)    Consistency Loss 7.8564e-01 (7.7490e-01)        Class Cross Entropy 1.6196e+00 (1.6133e+00)    Entropy 2.3005e+00 (2.3010e+00)
Epoch: [15][ 50/125]    Total Loss -3.8111e+00 (-3.8485e+00)    Consistency Loss 8.1201e-01 (7.7022e-01)        Class Cross Entropy 1.6241e+00 (1.6121e+00)    Entropy 2.3010e+00 (2.3009e+00)
Epoch: [15][ 75/125]    Total Loss -3.7951e+00 (-3.8451e+00)    Consistency Loss 7.8691e-01 (7.7375e-01)        Class Cross Entropy 1.6118e+00 (1.6123e+00)    Entropy 2.3008e+00 (2.3009e+00)
Epoch: [15][100/125]    Total Loss -3.8841e+00 (-3.8436e+00)    Consistency Loss 7.5077e-01 (7.7685e-01)        Class Cross Entropy 1.5983e+00 (1.6133e+00)    Entropy 2.3006e+00 (2.3008e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.22354793548583984
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3020875453948975, 'consistency': 0.6152607202529907, 'ce': 1.5093907117843628, 'total_loss': -0.17743611335754395}, {'entropy': 2.3020589351654053, 'consistency': 0.616618812084198, 'ce': 1.5096131563186646, 'total_loss': -0.17582696676254272}, {'entropy': 2.302042007446289, 'consistency': 0.6156814694404602, 'ce': 1.5094966888427734, 'total_loss': -0.17686384916305542}], 'lowest_loss_head': 0, 'lowest_loss': -0.17743611335754395}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8264, 'ARI': 0.6762074259242291, 'NMI': 0.7205973400756364, 'ACC Top-5': 0.9786, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: -0.1933 -> -0.1774
Best ACC on validation set: 0.8238 -> 0.8264
Lowest loss head is 0
Checkpoint ...
Epoch 17/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [16][  0/125]    Total Loss -3.7894e+00 (-3.7894e+00)    Consistency Loss 7.5363e-01 (7.5363e-01)        Class Cross Entropy 1.6036e+00 (1.6036e+00)    Entropy 2.3015e+00 (2.3015e+00)
Epoch: [16][ 25/125]    Total Loss -3.8160e+00 (-3.8239e+00)    Consistency Loss 7.6808e-01 (7.7206e-01)        Class Cross Entropy 1.6179e+00 (1.6129e+00)    Entropy 2.3007e+00 (2.3009e+00)
Epoch: [16][ 50/125]    Total Loss -3.9005e+00 (-3.8312e+00)    Consistency Loss 7.7187e-01 (7.7249e-01)        Class Cross Entropy 1.6057e+00 (1.6123e+00)    Entropy 2.3015e+00 (2.3008e+00)
Epoch: [16][ 75/125]    Total Loss -3.7825e+00 (-3.8375e+00)    Consistency Loss 7.7128e-01 (7.6934e-01)        Class Cross Entropy 1.6121e+00 (1.6114e+00)    Entropy 2.3020e+00 (2.3007e+00)
Epoch: [16][100/125]    Total Loss -3.8728e+00 (-3.8400e+00)    Consistency Loss 7.5824e-01 (7.6669e-01)        Class Cross Entropy 1.6167e+00 (1.6109e+00)    Entropy 2.3007e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1566615104675293
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3011515140533447, 'consistency': 0.6119951009750366, 'ce': 1.509262204170227, 'total_loss': -0.17989420890808105}, {'entropy': 2.301154613494873, 'consistency': 0.6120861172676086, 'ce': 1.5093296766281128, 'total_loss': -0.1797388195991516}, {'entropy': 2.3011178970336914, 'consistency': 0.612064778804779, 'ce': 1.5093339681625366, 'total_loss': -0.17971915006637573}], 'lowest_loss_head': 0, 'lowest_loss': -0.17989420890808105}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8278, 'ARI': 0.678779009633632, 'NMI': 0.7241475973631637, 'ACC Top-5': 0.9755, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: -0.1774 -> -0.1799
Best ACC on validation set: 0.8264 -> 0.8278
Lowest loss head is 0
Checkpoint ...
Epoch 18/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [17][  0/125]    Total Loss -3.8571e+00 (-3.8571e+00)    Consistency Loss 7.5971e-01 (7.5971e-01)        Class Cross Entropy 1.6068e+00 (1.6068e+00)    Entropy 2.3014e+00 (2.3014e+00)
Epoch: [17][ 25/125]    Total Loss -3.8616e+00 (-3.8461e+00)    Consistency Loss 6.9765e-01 (7.6485e-01)        Class Cross Entropy 1.5922e+00 (1.6101e+00)    Entropy 2.3004e+00 (2.3007e+00)
Epoch: [17][ 50/125]    Total Loss -3.9091e+00 (-3.8459e+00)    Consistency Loss 7.3085e-01 (7.6063e-01)        Class Cross Entropy 1.6042e+00 (1.6093e+00)    Entropy 2.3010e+00 (2.3008e+00)
Epoch: [17][ 75/125]    Total Loss -3.8635e+00 (-3.8445e+00)    Consistency Loss 7.3443e-01 (7.6094e-01)        Class Cross Entropy 1.6059e+00 (1.6092e+00)    Entropy 2.2998e+00 (2.3007e+00)
Epoch: [17][100/125]    Total Loss -3.7148e+00 (-3.8441e+00)    Consistency Loss 7.5965e-01 (7.6149e-01)        Class Cross Entropy 1.6159e+00 (1.6095e+00)    Entropy 2.3002e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15875482559204102
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3007466793060303, 'consistency': 0.6018055081367493, 'ce': 1.5079172849655151, 'total_loss': -0.19102388620376587}, {'entropy': 2.300792932510376, 'consistency': 0.6032398343086243, 'ce': 1.5081255435943604, 'total_loss': -0.18942755460739136}, {'entropy': 2.3006842136383057, 'consistency': 0.6026372313499451, 'ce': 1.508047342300415, 'total_loss': -0.18999963998794556}], 'lowest_loss_head': 0, 'lowest_loss': -0.19102388620376587}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8315, 'ARI': 0.6841331797249249, 'NMI': 0.7280623289205526, 'ACC Top-5': 0.9726, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: -0.1799 -> -0.1910
Best ACC on validation set: 0.8278 -> 0.8315
Lowest loss head is 0
Checkpoint ...
Epoch 19/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [18][  0/125]    Total Loss -3.8473e+00 (-3.8473e+00)    Consistency Loss 7.3741e-01 (7.3741e-01)        Class Cross Entropy 1.6011e+00 (1.6011e+00)    Entropy 2.3003e+00 (2.3003e+00)
Epoch: [18][ 25/125]    Total Loss -3.8085e+00 (-3.8550e+00)    Consistency Loss 8.0624e-01 (7.5448e-01)        Class Cross Entropy 1.6190e+00 (1.6065e+00)    Entropy 2.3012e+00 (2.3002e+00)
Epoch: [18][ 50/125]    Total Loss -3.9085e+00 (-3.8396e+00)    Consistency Loss 8.1237e-01 (7.6226e-01)        Class Cross Entropy 1.6172e+00 (1.6090e+00)    Entropy 2.3011e+00 (2.3004e+00)
Epoch: [18][ 75/125]    Total Loss -3.7953e+00 (-3.8379e+00)    Consistency Loss 7.9452e-01 (7.6221e-01)        Class Cross Entropy 1.6225e+00 (1.6091e+00)    Entropy 2.2982e+00 (2.3004e+00)
Epoch: [18][100/125]    Total Loss -3.8703e+00 (-3.8355e+00)    Consistency Loss 7.0608e-01 (7.6569e-01)        Class Cross Entropy 1.5970e+00 (1.6095e+00)    Entropy 2.2988e+00 (2.3004e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.23331308364868164
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301565408706665, 'consistency': 0.6103844046592712, 'ce': 1.508307933807373, 'total_loss': -0.18287307024002075}, {'entropy': 2.301584482192993, 'consistency': 0.6087584495544434, 'ce': 1.5081394910812378, 'total_loss': -0.184686541557312}, {'entropy': 2.301504135131836, 'consistency': 0.6115623712539673, 'ce': 1.5085018873214722, 'total_loss': -0.18143987655639648}], 'lowest_loss_head': 1, 'lowest_loss': -0.184686541557312}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.831, 'ARI': 0.6828005769446343, 'NMI': 0.7268070867790838, 'ACC Top-5': 0.9723, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.1910 -> -0.1847
Lowest loss head is 0
Checkpoint ...
Epoch 20/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [19][  0/125]    Total Loss -3.8659e+00 (-3.8659e+00)    Consistency Loss 6.9952e-01 (6.9952e-01)        Class Cross Entropy 1.5967e+00 (1.5967e+00)    Entropy 2.3011e+00 (2.3011e+00)
Epoch: [19][ 25/125]    Total Loss -3.8012e+00 (-3.8342e+00)    Consistency Loss 7.8672e-01 (7.6349e-01)        Class Cross Entropy 1.6131e+00 (1.6097e+00)    Entropy 2.3004e+00 (2.3005e+00)
Epoch: [19][ 50/125]    Total Loss -3.8873e+00 (-3.8430e+00)    Consistency Loss 7.2108e-01 (7.5127e-01)        Class Cross Entropy 1.5938e+00 (1.6060e+00)    Entropy 2.3024e+00 (2.3007e+00)
Epoch: [19][ 75/125]    Total Loss -3.8492e+00 (-3.8494e+00)    Consistency Loss 7.8577e-01 (7.5206e-01)        Class Cross Entropy 1.6162e+00 (1.6063e+00)    Entropy 2.3006e+00 (2.3006e+00)
Epoch: [19][100/125]    Total Loss -3.8787e+00 (-3.8538e+00)    Consistency Loss 7.8085e-01 (7.5063e-01)        Class Cross Entropy 1.6125e+00 (1.6057e+00)    Entropy 2.3002e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1535649299621582
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.299516439437866, 'consistency': 0.5978524684906006, 'ce': 1.5077080726623535, 'total_loss': -0.1939558982849121}, {'entropy': 2.2995052337646484, 'consistency': 0.5986086130142212, 'ce': 1.5079001188278198, 'total_loss': -0.19299650192260742}, {'entropy': 2.299445152282715, 'consistency': 0.5971084833145142, 'ce': 1.5076814889907837, 'total_loss': -0.194655179977417}], 'lowest_loss_head': 2, 'lowest_loss': -0.194655179977417}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8341, 'ARI': 0.6891219706753307, 'NMI': 0.7347304610523163, 'ACC Top-5': 0.9724, 'hungarian_match': [(0, 2), (1, 8), (2, 5), (3, 9), (4, 7), (5, 4), (6, 1), (7, 3), (8, 0), (9, 6)]}
New lowest loss on validation set: -0.1910 -> -0.1947
Best ACC on validation set: 0.8315 -> 0.8341
Lowest loss head is 2
Checkpoint ...
Evaluate best model based on SCAN metric at the end
[0.5241, 0.6292, 0.7077, 0.7664, 0.7639, 0.7756, 0.7829, 0.7884, 0.7967, 0.8091, 0.8124, 0.8142, 0.8185, 0.818, 0.8238, 0.8264, 0.8278, 0.8315, 0.831, 0.8341]
[1.2705309391021729, 0.26914089918136597, -0.027217447757720947, -0.09307479858398438, -0.12364369630813599, -0.12920427322387695, -0.14426451921463013, -0.1481049656867981, -0.1630365252494812, -0.1637250781059265, -0.1801862120628357, -0.16239124536514282, -0.18484944105148315, -0.17122578620910645, -0.19327890872955322, -0.17743611335754395, -0.17989420890808105, -0.19102388620376587, -0.184686541557312, -0.194655179977417]

##############
(dcdc-py3) yxchen2@gpu-comp-101:~/NNM$ python scan.py --config_env configs/env.yml --config_exp configs/scan/scan_cifar10.yml --gpus 0 
{'setup': 'scan', 'criterion': 'scan', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 3, 'backbone': 'resnet18', 'train_db_name': 'cifar-10', 'val_db_name': 'cifar-10', 'num_classes': 10, 'num_neighbors': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'epochs': 5, 'batch_size': 400, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': './results/cifar-10/pretext', 'pretext_checkpoint': './results/cifar-10/pretext/checkpoint.pth.tar', 'pretext_model': './results/cifar-10/pretext/model.pth.tar', 'topk_neighbors_train_path': './results/cifar-10/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': './results/cifar-10/pretext/topk-val-neighbors.npy', 'scan_dir': './results/cifar-10/scan', 'scan_checkpoint': './results/cifar-10/scan/checkpoint.pth.tar', 'scan_model': './results/cifar-10/scan/model.pth.tar', 'selflabel_dir': './results/cifar-10/selflabel', 'selflabel_checkpoint': './results/cifar-10/selflabel/checkpoint.pth.tar', 'selflabel_model': './results/cifar-10/selflabel/model.pth.tar'}
Get dataset and dataloaders
Files already downloaded and verified
Files already downloaded and verified
Train transforms: Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=None)
    <data.augment.Augment object at 0x14ebee3e0850>
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
    <data.augment.Cutout object at 0x14ebee3e0650>
)
Validation transforms: Compose(
    CenterCrop(size=(32, 32))
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
Train samples 50000 - Val samples 10000
Get model
Data parallel will be used for acceleration purpose
Get optimizer
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001
)
Get loss
SCANLoss(
  (softmax): Softmax(dim=1)
  (bce): BCELoss()
  (ce): CrossEntropyLoss()
  (confidence_ce): ConfidenceBasedCE(
    (loss): MaskedCrossEntropyLoss()
    (softmax): Softmax(dim=1)
  )
)
Restart from checkpoint ./results/cifar-10/scan/checkpoint.pth.tar
Starting main loop
Epoch 1/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [0][  0/125]     Total Loss -3.9156e+00 (-3.9156e+00)    Consistency Loss 7.1895e-01 (7.1895e-01)        Class Cross Entropy 1.5971e+00 (1.5971e+00)     Entropy 2.3002e+00 (2.3002e+00)
Epoch: [0][ 25/125]     Total Loss -3.8390e+00 (-3.8696e+00)    Consistency Loss 7.3621e-01 (7.5289e-01)        Class Cross Entropy 1.6055e+00 (1.6065e+00)     Entropy 2.3002e+00 (2.3005e+00)
Epoch: [0][ 50/125]     Total Loss -3.8294e+00 (-3.8642e+00)    Consistency Loss 7.0076e-01 (7.4948e-01)        Class Cross Entropy 1.5989e+00 (1.6060e+00)     Entropy 2.3001e+00 (2.3006e+00)
Epoch: [0][ 75/125]     Total Loss -3.8668e+00 (-3.8620e+00)    Consistency Loss 7.4326e-01 (7.4897e-01)        Class Cross Entropy 1.6055e+00 (1.6060e+00)     Entropy 2.3004e+00 (2.3005e+00)
Epoch: [0][100/125]     Total Loss -3.8024e+00 (-3.8595e+00)    Consistency Loss 7.2002e-01 (7.4463e-01)        Class Cross Entropy 1.5991e+00 (1.6047e+00)     Entropy 2.3006e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.16138577461242676
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3010551929473877, 'consistency': 0.5971637964248657, 'ce': 1.507148265838623, 'total_loss': -0.19674313068389893}, {'entropy': 2.301006555557251, 'consistency': 0.5975788235664368, 'ce': 1.5072224140167236, 'total_loss': -0.19620531797409058}, {'entropy': 2.3010036945343018, 'consistency': 0.5988578796386719, 'ce': 1.5074416399002075, 'total_loss': -0.19470417499542236}], 'lowest_loss_head': 0, 'lowest_loss': -0.19674313068389893}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8328, 'ARI': 0.6857326578183697, 'NMI': 0.7294261326853806, 'ACC Top-5': 0.9735, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.1947 -> -0.1967
Lowest loss head is 2
Checkpoint ...
Epoch 2/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [1][  0/125]     Total Loss -3.8657e+00 (-3.8657e+00)    Consistency Loss 6.8557e-01 (6.8557e-01)        Class Cross Entropy 1.5924e+00 (1.5924e+00)     Entropy 2.3004e+00 (2.3004e+00)
Epoch: [1][ 25/125]     Total Loss -3.7284e+00 (-3.8269e+00)    Consistency Loss 8.3482e-01 (7.5422e-01)        Class Cross Entropy 1.6211e+00 (1.6067e+00)     Entropy 2.2993e+00 (2.3005e+00)
Epoch: [1][ 50/125]     Total Loss -3.8924e+00 (-3.8421e+00)    Consistency Loss 7.2485e-01 (7.4825e-01)        Class Cross Entropy 1.5980e+00 (1.6050e+00)     Entropy 2.3007e+00 (2.3005e+00)
Epoch: [1][ 75/125]     Total Loss -3.7375e+00 (-3.8546e+00)    Consistency Loss 7.8336e-01 (7.4345e-01)        Class Cross Entropy 1.6225e+00 (1.6044e+00)     Entropy 2.3013e+00 (2.3007e+00)
Epoch: [1][100/125]     Total Loss -3.8857e+00 (-3.8575e+00)    Consistency Loss 7.1050e-01 (7.4151e-01)        Class Cross Entropy 1.5883e+00 (1.6038e+00)     Entropy 2.3013e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15909409523010254
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301673650741577, 'consistency': 0.60914546251297, 'ce': 1.509208083152771, 'total_loss': -0.18332010507583618}, {'entropy': 2.301664113998413, 'consistency': 0.6088335514068604, 'ce': 1.5091887712478638, 'total_loss': -0.18364179134368896}, {'entropy': 2.3016512393951416, 'consistency': 0.6098839044570923, 'ce': 1.5093752145767212, 'total_loss': -0.18239212036132812}], 'lowest_loss_head': 1, 'lowest_loss': -0.18364179134368896}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8346, 'ARI': 0.6898044385891406, 'NMI': 0.733518570084559, 'ACC Top-5': 0.9758, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
New lowest loss on validation set: -0.1947 -> -0.1836
Best ACC on validation set: 0.8341 -> 0.8346
Lowest loss head is 1
Checkpoint ...
Epoch 3/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [2][  0/125]     Total Loss -3.8928e+00 (-3.8928e+00)    Consistency Loss 7.3403e-01 (7.3403e-01)        Class Cross Entropy 1.6020e+00 (1.6020e+00)     Entropy 2.3002e+00 (2.3002e+00)
Epoch: [2][ 25/125]     Total Loss -3.9427e+00 (-3.8860e+00)    Consistency Loss 7.1279e-01 (7.2375e-01)        Class Cross Entropy 1.6009e+00 (1.5992e+00)     Entropy 2.3005e+00 (2.3009e+00)
Epoch: [2][ 50/125]     Total Loss -3.8939e+00 (-3.8798e+00)    Consistency Loss 7.2386e-01 (7.2619e-01)        Class Cross Entropy 1.6023e+00 (1.6003e+00)     Entropy 2.3016e+00 (2.3007e+00)
Epoch: [2][ 75/125]     Total Loss -3.9490e+00 (-3.8724e+00)    Consistency Loss 7.1992e-01 (7.3232e-01)        Class Cross Entropy 1.6024e+00 (1.6017e+00)     Entropy 2.2994e+00 (2.3006e+00)
Epoch: [2][100/125]     Total Loss -3.8416e+00 (-3.8720e+00)    Consistency Loss 7.3413e-01 (7.3276e-01)        Class Cross Entropy 1.6030e+00 (1.6018e+00)     Entropy 2.3019e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15823626518249512
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3007566928863525, 'consistency': 0.5883587002754211, 'ce': 1.5062973499298096, 'total_loss': -0.20610064268112183}, {'entropy': 2.300797939300537, 'consistency': 0.5881674885749817, 'ce': 1.5062730312347412, 'total_loss': -0.2063574194908142}, {'entropy': 2.3007352352142334, 'consistency': 0.588062584400177, 'ce': 1.5062615871429443, 'total_loss': -0.20641106367111206}], 'lowest_loss_head': 2, 'lowest_loss': -0.20641106367111206}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8358, 'ARI': 0.6907078667663291, 'NMI': 0.7338003635262627, 'ACC Top-5': 0.9719, 'hungarian_match': [(0, 2), (1, 8), (2, 5), (3, 9), (4, 7), (5, 4), (6, 1), (7, 3), (8, 0), (9, 6)]}
New lowest loss on validation set: -0.1836 -> -0.2064
Best ACC on validation set: 0.8346 -> 0.8358
Lowest loss head is 2
Checkpoint ...
Epoch 4/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [3][  0/125]     Total Loss -3.8449e+00 (-3.8449e+00)    Consistency Loss 7.3614e-01 (7.3614e-01)        Class Cross Entropy 1.6010e+00 (1.6010e+00)     Entropy 2.3006e+00 (2.3006e+00)
Epoch: [3][ 25/125]     Total Loss -3.9157e+00 (-3.8764e+00)    Consistency Loss 7.6649e-01 (7.3206e-01)        Class Cross Entropy 1.6150e+00 (1.6010e+00)     Entropy 2.2988e+00 (2.3007e+00)
Epoch: [3][ 50/125]     Total Loss -3.8786e+00 (-3.8612e+00)    Consistency Loss 7.7060e-01 (7.4061e-01)        Class Cross Entropy 1.6086e+00 (1.6022e+00)     Entropy 2.3007e+00 (2.3007e+00)
Epoch: [3][ 75/125]     Total Loss -3.9077e+00 (-3.8548e+00)    Consistency Loss 7.5022e-01 (7.4425e-01)        Class Cross Entropy 1.6085e+00 (1.6033e+00)     Entropy 2.3014e+00 (2.3007e+00)
Epoch: [3][100/125]     Total Loss -3.7909e+00 (-3.8582e+00)    Consistency Loss 7.8440e-01 (7.4583e-01)        Class Cross Entropy 1.6088e+00 (1.6037e+00)     Entropy 2.3010e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.16038203239440918
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301666736602783, 'consistency': 0.6093096733093262, 'ce': 1.509128451347351, 'total_loss': -0.18322861194610596}, {'entropy': 2.30167818069458, 'consistency': 0.6099538207054138, 'ce': 1.5093040466308594, 'total_loss': -0.18242031335830688}, {'entropy': 2.3016695976257324, 'consistency': 0.6112203001976013, 'ce': 1.5094740390777588, 'total_loss': -0.18097525835037231}], 'lowest_loss_head': 0, 'lowest_loss': -0.18322861194610596}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8349, 'ARI': 0.6906852650868536, 'NMI': 0.7328347506229396, 'ACC Top-5': 0.9711, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.2064 -> -0.1832
Lowest loss head is 2
Checkpoint ...
Epoch 5/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [4][  0/125]     Total Loss -3.8515e+00 (-3.8515e+00)    Consistency Loss 7.1075e-01 (7.1075e-01)        Class Cross Entropy 1.5860e+00 (1.5860e+00)     Entropy 2.2996e+00 (2.2996e+00)
Epoch: [4][ 25/125]     Total Loss -3.8520e+00 (-3.8916e+00)    Consistency Loss 7.2933e-01 (7.2433e-01)        Class Cross Entropy 1.6014e+00 (1.5983e+00)     Entropy 2.3011e+00 (2.3005e+00)
Epoch: [4][ 50/125]     Total Loss -3.9104e+00 (-3.8834e+00)    Consistency Loss 7.2129e-01 (7.2596e-01)        Class Cross Entropy 1.5948e+00 (1.5991e+00)     Entropy 2.3014e+00 (2.3007e+00)
Epoch: [4][ 75/125]     Total Loss -3.9273e+00 (-3.8841e+00)    Consistency Loss 7.5032e-01 (7.2765e-01)        Class Cross Entropy 1.6030e+00 (1.5999e+00)     Entropy 2.3010e+00 (2.3008e+00)
Epoch: [4][100/125]     Total Loss -3.9523e+00 (-3.8903e+00)    Consistency Loss 6.9068e-01 (7.2547e-01)        Class Cross Entropy 1.5850e+00 (1.5995e+00)     Entropy 2.3008e+00 (2.3008e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15510821342468262
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3007919788360596, 'consistency': 0.5800026655197144, 'ce': 1.504445195198059, 'total_loss': -0.21634411811828613}, {'entropy': 2.3008077144622803, 'consistency': 0.5803294777870178, 'ce': 1.504453182220459, 'total_loss': -0.21602505445480347}, {'entropy': 2.300778388977051, 'consistency': 0.5800700783729553, 'ce': 1.504443645477295, 'total_loss': -0.21626466512680054}], 'lowest_loss_head': 0, 'lowest_loss': -0.21634411811828613}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8374, 'ARI': 0.6938813724876913, 'NMI': 0.7370754546470673, 'ACC Top-5': 0.977, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: -0.2064 -> -0.2163
Best ACC on validation set: 0.8358 -> 0.8374
Lowest loss head is 0
Checkpoint ...
Evaluate best model based on SCAN metric at the end
[0.8328, 0.8346, 0.8358, 0.8349, 0.8374]
[-0.19674313068389893, -0.18364179134368896, -0.20641106367111206, -0.18322861194610596, -0.21634411811828613]

############

(dcdc-py3) yxchen2@gpu-comp-101:~/NNM$ python scan.py --config_env configs/env.yml --config_exp configs/scan/scan_cifar10.yml --gpus 0 
{'setup': 'scan', 'criterion': 'scan', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 3, 'backbone': 'resnet18', 'train_db_name': 'cifar-10', 'val_db_name': 'cifar-10', 'num_classes': 10, 'num_neighbors': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'epochs': 5, 'batch_size': 400, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': './results/cifar-10/pretext', 'pretext_checkpoint': './results/cifar-10/pretext/checkpoint.pth.tar', 'pretext_model': './results/cifar-10/pretext/model.pth.tar', 'topk_neighbors_train_path': './results/cifar-10/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': './results/cifar-10/pretext/topk-val-neighbors.npy', 'scan_dir': './results/cifar-10/scan', 'scan_checkpoint': './results/cifar-10/scan/checkpoint.pth.tar', 'scan_model': './results/cifar-10/scan/model.pth.tar', 'selflabel_dir': './results/cifar-10/selflabel', 'selflabel_checkpoint': './results/cifar-10/selflabel/checkpoint.pth.tar', 'selflabel_model': './results/cifar-10/selflabel/model.pth.tar'}
Get dataset and dataloaders
Files already downloaded and verified
Files already downloaded and verified
Train transforms: Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=None)
    <data.augment.Augment object at 0x153421647710>
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
    <data.augment.Cutout object at 0x1534216476d0>
)
Validation transforms: Compose(
    CenterCrop(size=(32, 32))
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
Train samples 50000 - Val samples 10000
Get model
Data parallel will be used for acceleration purpose
Get optimizer
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001
)
Get loss
SCANLoss(
  (softmax): Softmax(dim=1)
  (bce): BCELoss()
  (ce): CrossEntropyLoss()
  (confidence_ce): ConfidenceBasedCE(
    (loss): MaskedCrossEntropyLoss()
    (softmax): Softmax(dim=1)
  )
)
Restart from checkpoint ./results/cifar-10/scan/checkpoint.pth.tar
Starting main loop
Epoch 1/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [0][  0/125]     Total Loss -3.9365e+00 (-3.9365e+00)    Consistency Loss 6.4622e-01 (6.4622e-01)        Class Cross Entropy 1.5777e+00 (1.5777e+00)     Entropy 2.3010e+00 (2.3010e+00)
Epoch: [0][ 25/125]     Total Loss -3.9216e+00 (-3.8599e+00)    Consistency Loss 7.2345e-01 (7.3242e-01)        Class Cross Entropy 1.5934e+00 (1.5995e+00)     Entropy 2.3019e+00 (2.3006e+00)
Epoch: [0][ 50/125]     Total Loss -3.8042e+00 (-3.8553e+00)    Consistency Loss 7.2885e-01 (7.3660e-01)        Class Cross Entropy 1.5977e+00 (1.6010e+00)     Entropy 2.3023e+00 (2.3005e+00)
Epoch: [0][ 75/125]     Total Loss -3.8838e+00 (-3.8585e+00)    Consistency Loss 7.2835e-01 (7.3983e-01)        Class Cross Entropy 1.5984e+00 (1.6012e+00)     Entropy 2.3014e+00 (2.3006e+00)
Epoch: [0][100/125]     Total Loss -3.7903e+00 (-3.8579e+00)    Consistency Loss 7.3220e-01 (7.4042e-01)        Class Cross Entropy 1.6007e+00 (1.6015e+00)     Entropy 2.3016e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15529775619506836
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.298818349838257, 'consistency': 0.6193877458572388, 'ce': 1.5108840465545654, 'total_loss': -0.16854655742645264}, {'entropy': 2.298816204071045, 'consistency': 0.6184121966362, 'ce': 1.5107691287994385, 'total_loss': -0.1696348786354065}, {'entropy': 2.2987377643585205, 'consistency': 0.6194873452186584, 'ce': 1.5109012126922607, 'total_loss': -0.16834920644760132}], 'lowest_loss_head': 1, 'lowest_loss': -0.1696348786354065}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8336, 'ARI': 0.685672408839243, 'NMI': 0.7322916226243525, 'ACC Top-5': 0.9733, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.2163 -> -0.1696
Lowest loss head is 0
Checkpoint ...
Epoch 2/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [1][  0/125]     Total Loss -3.9649e+00 (-3.9649e+00)    Consistency Loss 6.7178e-01 (6.7178e-01)        Class Cross Entropy 1.5845e+00 (1.5845e+00)     Entropy 2.2996e+00 (2.2996e+00)
Epoch: [1][ 25/125]     Total Loss -3.9071e+00 (-3.9022e+00)    Consistency Loss 6.8456e-01 (7.2188e-01)        Class Cross Entropy 1.5901e+00 (1.5980e+00)     Entropy 2.3003e+00 (2.3004e+00)
Epoch: [1][ 50/125]     Total Loss -3.9756e+00 (-3.8938e+00)    Consistency Loss 6.8853e-01 (7.2355e-01)        Class Cross Entropy 1.5934e+00 (1.5987e+00)     Entropy 2.3011e+00 (2.3006e+00)
Epoch: [1][ 75/125]     Total Loss -3.8580e+00 (-3.8993e+00)    Consistency Loss 7.0812e-01 (7.1929e-01)        Class Cross Entropy 1.5941e+00 (1.5977e+00)     Entropy 2.3012e+00 (2.3006e+00)
Epoch: [1][100/125]     Total Loss -3.8540e+00 (-3.9035e+00)    Consistency Loss 7.4526e-01 (7.1699e-01)        Class Cross Entropy 1.6043e+00 (1.5975e+00)     Entropy 2.3020e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1613321304321289
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301248788833618, 'consistency': 0.5941687226295471, 'ce': 1.5062634944915771, 'total_loss': -0.2008165717124939}, {'entropy': 2.301279306411743, 'consistency': 0.5936751365661621, 'ce': 1.506239891052246, 'total_loss': -0.20136427879333496}, {'entropy': 2.301295042037964, 'consistency': 0.5957714915275574, 'ce': 1.506568431854248, 'total_loss': -0.19895511865615845}], 'lowest_loss_head': 1, 'lowest_loss': -0.20136427879333496}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8365, 'ARI': 0.6915797053565601, 'NMI': 0.7354878190986319, 'ACC Top-5': 0.9785, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.2163 -> -0.2014
Lowest loss head is 0
Checkpoint ...
Epoch 3/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [2][  0/125]     Total Loss -3.7358e+00 (-3.7358e+00)    Consistency Loss 7.9510e-01 (7.9510e-01)        Class Cross Entropy 1.6197e+00 (1.6197e+00)     Entropy 2.3005e+00 (2.3005e+00)
Epoch: [2][ 25/125]     Total Loss -3.8423e+00 (-3.8509e+00)    Consistency Loss 7.5142e-01 (7.2626e-01)        Class Cross Entropy 1.6093e+00 (1.5992e+00)     Entropy 2.3018e+00 (2.3007e+00)
Epoch: [2][ 50/125]     Total Loss -3.7404e+00 (-3.8546e+00)    Consistency Loss 7.9022e-01 (7.2785e-01)        Class Cross Entropy 1.6113e+00 (1.5987e+00)     Entropy 2.3016e+00 (2.3007e+00)
Epoch: [2][ 75/125]     Total Loss -3.8168e+00 (-3.8597e+00)    Consistency Loss 7.6187e-01 (7.3127e-01)        Class Cross Entropy 1.6107e+00 (1.5992e+00)     Entropy 2.3010e+00 (2.3007e+00)
Epoch: [2][100/125]     Total Loss -3.8955e+00 (-3.8618e+00)    Consistency Loss 7.0902e-01 (7.3153e-01)        Class Cross Entropy 1.5879e+00 (1.5994e+00)     Entropy 2.3000e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1616218090057373
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3004462718963623, 'consistency': 0.6170927286148071, 'ce': 1.5101910829544067, 'total_loss': -0.17316246032714844}, {'entropy': 2.300558090209961, 'consistency': 0.6192124485969543, 'ce': 1.5105175971984863, 'total_loss': -0.17082804441452026}, {'entropy': 2.3004891872406006, 'consistency': 0.6177935004234314, 'ce': 1.5103198289871216, 'total_loss': -0.1723758578300476}], 'lowest_loss_head': 0, 'lowest_loss': -0.17316246032714844}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8342, 'ARI': 0.6871710749842821, 'NMI': 0.733830198284295, 'ACC Top-5': 0.9742, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.2163 -> -0.1732
Lowest loss head is 0
Checkpoint ...
Epoch 4/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [3][  0/125]     Total Loss -3.7880e+00 (-3.7880e+00)    Consistency Loss 7.6288e-01 (7.6288e-01)        Class Cross Entropy 1.6061e+00 (1.6061e+00)     Entropy 2.2999e+00 (2.2999e+00)
Epoch: [3][ 25/125]     Total Loss -3.9085e+00 (-3.9042e+00)    Consistency Loss 7.4045e-01 (7.1067e-01)        Class Cross Entropy 1.6019e+00 (1.5952e+00)     Entropy 2.2999e+00 (2.3002e+00)
Epoch: [3][ 50/125]     Total Loss -3.6850e+00 (-3.9100e+00)    Consistency Loss 7.3194e-01 (7.0434e-01)        Class Cross Entropy 1.6033e+00 (1.5941e+00)     Entropy 2.3020e+00 (2.3003e+00)
Epoch: [3][ 75/125]     Total Loss -3.8811e+00 (-3.9084e+00)    Consistency Loss 7.2358e-01 (7.0111e-01)        Class Cross Entropy 1.5983e+00 (1.5933e+00)     Entropy 2.2991e+00 (2.3005e+00)
Epoch: [3][100/125]     Total Loss -3.9317e+00 (-3.9056e+00)    Consistency Loss 7.1766e-01 (7.0439e-01)        Class Cross Entropy 1.5927e+00 (1.5944e+00)     Entropy 2.3018e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.16235637664794922
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.300506114959717, 'consistency': 0.5867244601249695, 'ce': 1.5067161321640015, 'total_loss': -0.20706552267074585}, {'entropy': 2.300485610961914, 'consistency': 0.585839569568634, 'ce': 1.5065500736236572, 'total_loss': -0.2080959677696228}, {'entropy': 2.30047345161438, 'consistency': 0.5877414345741272, 'ce': 1.5068418979644775, 'total_loss': -0.20589011907577515}], 'lowest_loss_head': 1, 'lowest_loss': -0.2080959677696228}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8331, 'ARI': 0.6878917547109334, 'NMI': 0.7340320207995694, 'ACC Top-5': 0.978, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.2163 -> -0.2081
Lowest loss head is 0
Checkpoint ...
Epoch 5/5
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [4][  0/125]     Total Loss -3.8886e+00 (-3.8886e+00)    Consistency Loss 7.6497e-01 (7.6497e-01)        Class Cross Entropy 1.6047e+00 (1.6047e+00)     Entropy 2.2981e+00 (2.2981e+00)
Epoch: [4][ 25/125]     Total Loss -3.8859e+00 (-3.8744e+00)    Consistency Loss 7.1256e-01 (7.2682e-01)        Class Cross Entropy 1.5897e+00 (1.5987e+00)     Entropy 2.3009e+00 (2.3006e+00)
Epoch: [4][ 50/125]     Total Loss -3.9439e+00 (-3.8672e+00)    Consistency Loss 7.0091e-01 (7.2969e-01)        Class Cross Entropy 1.5899e+00 (1.5989e+00)     Entropy 2.3013e+00 (2.3007e+00)
Epoch: [4][ 75/125]     Total Loss -3.9823e+00 (-3.8729e+00)    Consistency Loss 6.6595e-01 (7.2501e-01)        Class Cross Entropy 1.5776e+00 (1.5976e+00)     Entropy 2.2997e+00 (2.3007e+00)
Epoch: [4][100/125]     Total Loss -3.8809e+00 (-3.8747e+00)    Consistency Loss 6.9804e-01 (7.2733e-01)        Class Cross Entropy 1.5924e+00 (1.5983e+00)     Entropy 2.3008e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1595776081085205
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3009369373321533, 'consistency': 0.6221129298210144, 'ce': 1.5100491046905518, 'total_loss': -0.16877490282058716}, {'entropy': 2.300968647003174, 'consistency': 0.6224157810211182, 'ce': 1.510084867477417, 'total_loss': -0.16846799850463867}, {'entropy': 2.300926446914673, 'consistency': 0.6226601004600525, 'ce': 1.5101182460784912, 'total_loss': -0.16814810037612915}], 'lowest_loss_head': 0, 'lowest_loss': -0.16877490282058716}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8369, 'ARI': 0.6929332351633622, 'NMI': 0.7373187535636018, 'ACC Top-5': 0.9738, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.2163 -> -0.1688
Lowest loss head is 0
Checkpoint ...
Evaluate best model based on SCAN metric at the end
[0.8336, 0.8365, 0.8342, 0.8331, 0.8369]
[-0.1696348786354065, -0.20136427879333496, -0.17316246032714844, -0.2080959677696228, -0.16877490282058716]

############

(dcdc-py3) yxchen2@gpu-comp-101:~/NNM$ python scan.py --config_env configs/env.yml --config_exp configs/scan/scan_cifar10.yml --gpus 0 
{'setup': 'scan', 'criterion': 'scan', 'criterion_kwargs': {'entropy_weight': 5.0}, 'update_cluster_head_only': False, 'num_heads': 3, 'backbone': 'resnet18', 'train_db_name': 'cifar-10', 'val_db_name': 'cifar-10', 'num_classes': 10, 'num_neighbors': 20, 'augmentation_strategy': 'ours', 'augmentation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}, 'num_strong_augs': 4, 'cutout_kwargs': {'n_holes': 1, 'length': 16, 'random': True}}, 'transformation_kwargs': {'crop_size': 32, 'normalize': {'mean': [0.4914, 0.4822, 0.4465], 'std': [0.2023, 0.1994, 0.201]}}, 'optimizer': 'adam', 'optimizer_kwargs': {'lr': 0.0001, 'weight_decay': 0.0001}, 'epochs': 20, 'batch_size': 400, 'num_workers': 8, 'scheduler': 'constant', 'pretext_dir': './results/cifar-10/pretext', 'pretext_checkpoint': './results/cifar-10/pretext/checkpoint.pth.tar', 'pretext_model': './results/cifar-10/pretext/model.pth.tar', 'topk_neighbors_train_path': './results/cifar-10/pretext/topk-train-neighbors.npy', 'topk_neighbors_val_path': './results/cifar-10/pretext/topk-val-neighbors.npy', 'scan_dir': './results/cifar-10/scan', 'scan_checkpoint': './results/cifar-10/scan/checkpoint.pth.tar', 'scan_model': './results/cifar-10/scan/model.pth.tar', 'selflabel_dir': './results/cifar-10/selflabel', 'selflabel_checkpoint': './results/cifar-10/selflabel/checkpoint.pth.tar', 'selflabel_model': './results/cifar-10/selflabel/model.pth.tar'}
Get dataset and dataloaders
Files already downloaded and verified
Files already downloaded and verified
Train transforms: Compose(
    RandomHorizontalFlip(p=0.5)
    RandomCrop(size=(32, 32), padding=None)
    <data.augment.Augment object at 0x14d0201588d0>
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
    <data.augment.Cutout object at 0x14d020158850>
)
Validation transforms: Compose(
    CenterCrop(size=(32, 32))
    ToTensor()
    Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.201])
)
Train samples 50000 - Val samples 10000
Get model
Data parallel will be used for acceleration purpose
Get optimizer
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0001
    weight_decay: 0.0001
)
Get loss
SCANLoss(
  (softmax): Softmax(dim=1)
  (bce): BCELoss()
  (ce): CrossEntropyLoss()
  (confidence_ce): ConfidenceBasedCE(
    (loss): MaskedCrossEntropyLoss()
    (softmax): Softmax(dim=1)
  )
)
Restart from checkpoint ./results/cifar-10/scan/checkpoint.pth.tar
Starting main loop
Epoch 1/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [0][  0/125]     Total Loss -3.9424e+00 (-3.9424e+00)    Consistency Loss 7.7157e-01 (7.7157e-01)        Class Cross Entropy 1.6070e+00 (1.6070e+00)     Entropy 2.2981e+00 (2.2981e+00)
Epoch: [0][ 25/125]     Total Loss -3.9468e+00 (-3.9134e+00)    Consistency Loss 7.2076e-01 (7.1498e-01)        Class Cross Entropy 1.6022e+00 (1.5972e+00)     Entropy 2.2997e+00 (2.3006e+00)
Epoch: [0][ 50/125]     Total Loss -4.0144e+00 (-3.9134e+00)    Consistency Loss 7.1063e-01 (7.1187e-01)        Class Cross Entropy 1.5991e+00 (1.5967e+00)     Entropy 2.3013e+00 (2.3009e+00)
Epoch: [0][ 75/125]     Total Loss -4.0426e+00 (-3.9132e+00)    Consistency Loss 6.6378e-01 (7.0770e-01)        Class Cross Entropy 1.5767e+00 (1.5953e+00)     Entropy 2.3005e+00 (2.3007e+00)
Epoch: [0][100/125]     Total Loss -3.9003e+00 (-3.9126e+00)    Consistency Loss 7.3218e-01 (7.0693e-01)        Class Cross Entropy 1.6005e+00 (1.5954e+00)     Entropy 2.3010e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15517354011535645
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3019402027130127, 'consistency': 0.5857489109039307, 'ce': 1.50541090965271, 'total_loss': -0.21078038215637207}, {'entropy': 2.3019371032714844, 'consistency': 0.5865769982337952, 'ce': 1.50551176071167, 'total_loss': -0.2098483443260193}, {'entropy': 2.301938056945801, 'consistency': 0.5868769288063049, 'ce': 1.5056116580963135, 'total_loss': -0.20944947004318237}], 'lowest_loss_head': 0, 'lowest_loss': -0.21078038215637207}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8406, 'ARI': 0.6994999041400556, 'NMI': 0.739718392031597, 'ACC Top-5': 0.9808, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: -0.2163 -> -0.2108
Best ACC on validation set: 0.8374 -> 0.8406
Lowest loss head is 0
Checkpoint ...
Epoch 2/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [1][  0/125]     Total Loss -3.8169e+00 (-3.8169e+00)    Consistency Loss 6.7306e-01 (6.7306e-01)        Class Cross Entropy 1.5863e+00 (1.5863e+00)     Entropy 2.3007e+00 (2.3007e+00)
Epoch: [1][ 25/125]     Total Loss -3.9294e+00 (-3.8770e+00)    Consistency Loss 6.8211e-01 (7.1504e-01)        Class Cross Entropy 1.5855e+00 (1.5957e+00)     Entropy 2.3019e+00 (2.3006e+00)
Epoch: [1][ 50/125]     Total Loss -3.8379e+00 (-3.8805e+00)    Consistency Loss 7.5974e-01 (7.1936e-01)        Class Cross Entropy 1.6079e+00 (1.5960e+00)     Entropy 2.3015e+00 (2.3005e+00)
Epoch: [1][ 75/125]     Total Loss -3.8263e+00 (-3.8823e+00)    Consistency Loss 7.0640e-01 (7.1905e-01)        Class Cross Entropy 1.5936e+00 (1.5953e+00)     Entropy 2.3013e+00 (2.3005e+00)
Epoch: [1][100/125]     Total Loss -3.9638e+00 (-3.8839e+00)    Consistency Loss 6.8957e-01 (7.1968e-01)        Class Cross Entropy 1.5853e+00 (1.5956e+00)     Entropy 2.3020e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15514206886291504
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301936388015747, 'consistency': 0.6221231818199158, 'ce': 1.5101737976074219, 'total_loss': -0.16963940858840942}, {'entropy': 2.301913261413574, 'consistency': 0.6205289959907532, 'ce': 1.5099406242370605, 'total_loss': -0.1714436411857605}, {'entropy': 2.3019309043884277, 'consistency': 0.6231617331504822, 'ce': 1.5103334188461304, 'total_loss': -0.16843575239181519}], 'lowest_loss_head': 1, 'lowest_loss': -0.1714436411857605}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8389, 'ARI': 0.6978196384629789, 'NMI': 0.7417107718696057, 'ACC Top-5': 0.9751, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.2108 -> -0.1714
Lowest loss head is 0
Checkpoint ...
Epoch 3/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [2][  0/125]     Total Loss -3.9252e+00 (-3.9252e+00)    Consistency Loss 6.8272e-01 (6.8272e-01)        Class Cross Entropy 1.5863e+00 (1.5863e+00)     Entropy 2.3017e+00 (2.3017e+00)
Epoch: [2][ 25/125]     Total Loss -3.9330e+00 (-3.9184e+00)    Consistency Loss 7.6405e-01 (6.9554e-01)        Class Cross Entropy 1.6011e+00 (1.5920e+00)     Entropy 2.2995e+00 (2.3006e+00)
Epoch: [2][ 50/125]     Total Loss -3.8635e+00 (-3.9055e+00)    Consistency Loss 7.1983e-01 (6.9908e-01)        Class Cross Entropy 1.5957e+00 (1.5928e+00)     Entropy 2.3008e+00 (2.3007e+00)
Epoch: [2][ 75/125]     Total Loss -3.9362e+00 (-3.9024e+00)    Consistency Loss 7.3651e-01 (6.9979e-01)        Class Cross Entropy 1.6014e+00 (1.5930e+00)     Entropy 2.2979e+00 (2.3007e+00)
Epoch: [2][100/125]     Total Loss -3.7800e+00 (-3.8976e+00)    Consistency Loss 7.4989e-01 (7.0374e-01)        Class Cross Entropy 1.6059e+00 (1.5940e+00)     Entropy 2.3000e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15399456024169922
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3019115924835205, 'consistency': 0.5864763855934143, 'ce': 1.5057438611984253, 'total_loss': -0.2096913456916809}, {'entropy': 2.3019022941589355, 'consistency': 0.5875930190086365, 'ce': 1.505981683731079, 'total_loss': -0.20832759141921997}, {'entropy': 2.301927089691162, 'consistency': 0.5871860384941101, 'ce': 1.5058948993682861, 'total_loss': -0.20884615182876587}], 'lowest_loss_head': 0, 'lowest_loss': -0.2096913456916809}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8368, 'ARI': 0.6949943909326334, 'NMI': 0.7362810673651806, 'ACC Top-5': 0.9763, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.2108 -> -0.2097
Lowest loss head is 0
Checkpoint ...
Epoch 4/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [3][  0/125]     Total Loss -3.7636e+00 (-3.7636e+00)    Consistency Loss 7.9106e-01 (7.9106e-01)        Class Cross Entropy 1.6207e+00 (1.6207e+00)     Entropy 2.3003e+00 (2.3003e+00)
Epoch: [3][ 25/125]     Total Loss -4.0523e+00 (-3.8729e+00)    Consistency Loss 6.6543e-01 (7.1950e-01)        Class Cross Entropy 1.5775e+00 (1.5967e+00)     Entropy 2.3014e+00 (2.3004e+00)
Epoch: [3][ 50/125]     Total Loss -3.8179e+00 (-3.8745e+00)    Consistency Loss 7.3542e-01 (7.1940e-01)        Class Cross Entropy 1.6056e+00 (1.5964e+00)     Entropy 2.3000e+00 (2.3004e+00)
Epoch: [3][ 75/125]     Total Loss -3.8263e+00 (-3.8789e+00)    Consistency Loss 7.0690e-01 (7.1938e-01)        Class Cross Entropy 1.5935e+00 (1.5960e+00)     Entropy 2.3000e+00 (2.3005e+00)
Epoch: [3][100/125]     Total Loss -3.9278e+00 (-3.8793e+00)    Consistency Loss 7.2302e-01 (7.2120e-01)        Class Cross Entropy 1.5940e+00 (1.5960e+00)     Entropy 2.3006e+00 (2.3005e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1565384864807129
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3019392490386963, 'consistency': 0.6094905734062195, 'ce': 1.5097596645355225, 'total_loss': -0.18268901109695435}, {'entropy': 2.3019020557403564, 'consistency': 0.6088435053825378, 'ce': 1.509688377380371, 'total_loss': -0.1833701729774475}, {'entropy': 2.301919937133789, 'consistency': 0.6104885935783386, 'ce': 1.5099292993545532, 'total_loss': -0.18150204420089722}], 'lowest_loss_head': 1, 'lowest_loss': -0.1833701729774475}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8394, 'ARI': 0.6983950436897014, 'NMI': 0.740988130245009, 'ACC Top-5': 0.9762, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.2108 -> -0.1834
Lowest loss head is 0
Checkpoint ...
Epoch 5/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [4][  0/125]     Total Loss -3.9001e+00 (-3.9001e+00)    Consistency Loss 6.9248e-01 (6.9248e-01)        Class Cross Entropy 1.5916e+00 (1.5916e+00)     Entropy 2.3007e+00 (2.3007e+00)
Epoch: [4][ 25/125]     Total Loss -3.8751e+00 (-3.8816e+00)    Consistency Loss 7.7666e-01 (7.1037e-01)        Class Cross Entropy 1.6124e+00 (1.5949e+00)     Entropy 2.3018e+00 (2.3004e+00)
Epoch: [4][ 50/125]     Total Loss -3.8296e+00 (-3.8874e+00)    Consistency Loss 7.6189e-01 (7.1064e-01)        Class Cross Entropy 1.6050e+00 (1.5950e+00)     Entropy 2.3001e+00 (2.3005e+00)
Epoch: [4][ 75/125]     Total Loss -3.8524e+00 (-3.8896e+00)    Consistency Loss 7.5061e-01 (7.0991e-01)        Class Cross Entropy 1.6050e+00 (1.5947e+00)     Entropy 2.3000e+00 (2.3005e+00)
Epoch: [4][100/125]     Total Loss -3.8791e+00 (-3.8898e+00)    Consistency Loss 6.4799e-01 (7.0925e-01)        Class Cross Entropy 1.5809e+00 (1.5943e+00)     Entropy 2.3009e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.16305112838745117
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3009097576141357, 'consistency': 0.599475622177124, 'ce': 1.507213830947876, 'total_loss': -0.19422030448913574}, {'entropy': 2.3008339405059814, 'consistency': 0.5985717177391052, 'ce': 1.5070762634277344, 'total_loss': -0.19518595933914185}, {'entropy': 2.300872564315796, 'consistency': 0.5982357263565063, 'ce': 1.5070570707321167, 'total_loss': -0.19557976722717285}], 'lowest_loss_head': 2, 'lowest_loss': -0.19557976722717285}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8369, 'ARI': 0.6944751052499515, 'NMI': 0.7378834495566475, 'ACC Top-5': 0.9715, 'hungarian_match': [(0, 2), (1, 8), (2, 5), (3, 9), (4, 7), (5, 4), (6, 1), (7, 3), (8, 0), (9, 6)]}
No new lowest loss on validation set: -0.2108 -> -0.1956
Lowest loss head is 0
Checkpoint ...
Epoch 6/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [5][  0/125]     Total Loss -3.9544e+00 (-3.9544e+00)    Consistency Loss 7.1768e-01 (7.1768e-01)        Class Cross Entropy 1.5952e+00 (1.5952e+00)     Entropy 2.3007e+00 (2.3007e+00)
Epoch: [5][ 25/125]     Total Loss -3.9680e+00 (-3.8983e+00)    Consistency Loss 6.7046e-01 (7.0743e-01)        Class Cross Entropy 1.5835e+00 (1.5947e+00)     Entropy 2.3005e+00 (2.3010e+00)
Epoch: [5][ 50/125]     Total Loss -3.9400e+00 (-3.8948e+00)    Consistency Loss 7.6995e-01 (7.0982e-01)        Class Cross Entropy 1.6025e+00 (1.5947e+00)     Entropy 2.3001e+00 (2.3007e+00)
Epoch: [5][ 75/125]     Total Loss -3.8434e+00 (-3.9009e+00)    Consistency Loss 6.7990e-01 (7.0842e-01)        Class Cross Entropy 1.5844e+00 (1.5941e+00)     Entropy 2.3010e+00 (2.3007e+00)
Epoch: [5][100/125]     Total Loss -3.8698e+00 (-3.9022e+00)    Consistency Loss 6.8542e-01 (7.0699e-01)        Class Cross Entropy 1.5873e+00 (1.5938e+00)     Entropy 2.3015e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.23500967025756836
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3017563819885254, 'consistency': 0.5806455016136169, 'ce': 1.5051862001419067, 'total_loss': -0.2159246802330017}, {'entropy': 2.3017613887786865, 'consistency': 0.5817383527755737, 'ce': 1.505375862121582, 'total_loss': -0.21464717388153076}, {'entropy': 2.3017354011535645, 'consistency': 0.5840082168579102, 'ce': 1.5057023763656616, 'total_loss': -0.21202480792999268}], 'lowest_loss_head': 0, 'lowest_loss': -0.2159246802330017}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8402, 'ARI': 0.6983302832743519, 'NMI': 0.7416234941281246, 'ACC Top-5': 0.9793, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.2108 -> -0.2159
Lowest loss head is 0
Checkpoint ...
Epoch 7/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [6][  0/125]     Total Loss -3.8638e+00 (-3.8638e+00)    Consistency Loss 7.1693e-01 (7.1693e-01)        Class Cross Entropy 1.5945e+00 (1.5945e+00)     Entropy 2.3015e+00 (2.3015e+00)
Epoch: [6][ 25/125]     Total Loss -3.9096e+00 (-3.8770e+00)    Consistency Loss 6.8334e-01 (7.0907e-01)        Class Cross Entropy 1.5890e+00 (1.5930e+00)     Entropy 2.3006e+00 (2.3005e+00)
Epoch: [6][ 50/125]     Total Loss -3.8238e+00 (-3.8766e+00)    Consistency Loss 7.1417e-01 (7.1602e-01)        Class Cross Entropy 1.5985e+00 (1.5942e+00)     Entropy 2.3017e+00 (2.3006e+00)
Epoch: [6][ 75/125]     Total Loss -3.8749e+00 (-3.8763e+00)    Consistency Loss 7.2118e-01 (7.1405e-01)        Class Cross Entropy 1.5884e+00 (1.5937e+00)     Entropy 2.2993e+00 (2.3005e+00)
Epoch: [6][100/125]     Total Loss -3.8995e+00 (-3.8804e+00)    Consistency Loss 6.7007e-01 (7.1189e-01)        Class Cross Entropy 1.5763e+00 (1.5929e+00)     Entropy 2.3001e+00 (2.3005e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.16385483741760254
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301919460296631, 'consistency': 0.6113024353981018, 'ce': 1.5093845129013062, 'total_loss': -0.1812325119972229}, {'entropy': 2.301882266998291, 'consistency': 0.6104820370674133, 'ce': 1.5092837810516357, 'total_loss': -0.18211644887924194}, {'entropy': 2.3018875122070312, 'consistency': 0.6084299087524414, 'ce': 1.50898277759552, 'total_loss': -0.18447482585906982}], 'lowest_loss_head': 2, 'lowest_loss': -0.18447482585906982}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8385, 'ARI': 0.697110335396192, 'NMI': 0.7404726115978456, 'ACC Top-5': 0.9751, 'hungarian_match': [(0, 2), (1, 8), (2, 5), (3, 9), (4, 7), (5, 4), (6, 1), (7, 3), (8, 0), (9, 6)]}
No new lowest loss on validation set: -0.2108 -> -0.1845
Lowest loss head is 0
Checkpoint ...
Epoch 8/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [7][  0/125]     Total Loss -3.8137e+00 (-3.8137e+00)    Consistency Loss 7.3144e-01 (7.3144e-01)        Class Cross Entropy 1.6007e+00 (1.6007e+00)     Entropy 2.3016e+00 (2.3016e+00)
Epoch: [7][ 25/125]     Total Loss -3.8928e+00 (-3.9124e+00)    Consistency Loss 7.2621e-01 (6.9911e-01)        Class Cross Entropy 1.6039e+00 (1.5922e+00)     Entropy 2.3013e+00 (2.3008e+00)
Epoch: [7][ 50/125]     Total Loss -3.8883e+00 (-3.9118e+00)    Consistency Loss 6.8166e-01 (6.9456e-01)        Class Cross Entropy 1.5942e+00 (1.5906e+00)     Entropy 2.3003e+00 (2.3008e+00)
Epoch: [7][ 75/125]     Total Loss -3.9048e+00 (-3.9028e+00)    Consistency Loss 6.7298e-01 (6.9785e-01)        Class Cross Entropy 1.5777e+00 (1.5915e+00)     Entropy 2.2994e+00 (2.3008e+00)
Epoch: [7][100/125]     Total Loss -3.8707e+00 (-3.9061e+00)    Consistency Loss 6.8142e-01 (6.9741e-01)        Class Cross Entropy 1.5873e+00 (1.5916e+00)     Entropy 2.3000e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1554121971130371
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3020853996276855, 'consistency': 0.5899035930633545, 'ce': 1.5068055391311646, 'total_loss': -0.2053762674331665}, {'entropy': 2.3020713329315186, 'consistency': 0.5910537838935852, 'ce': 1.5070031881332397, 'total_loss': -0.2040143609046936}, {'entropy': 2.3020570278167725, 'consistency': 0.5928762555122375, 'ce': 1.5072786808013916, 'total_loss': -0.2019020915031433}], 'lowest_loss_head': 0, 'lowest_loss': -0.2053762674331665}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8419, 'ARI': 0.7025397106097614, 'NMI': 0.744087667372403, 'ACC Top-5': 0.9792, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
New lowest loss on validation set: -0.2108 -> -0.2054
Best ACC on validation set: 0.8406 -> 0.8419
Lowest loss head is 0
Checkpoint ...
Epoch 9/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [8][  0/125]     Total Loss -3.9865e+00 (-3.9865e+00)    Consistency Loss 6.7079e-01 (6.7079e-01)        Class Cross Entropy 1.5779e+00 (1.5779e+00)     Entropy 2.3011e+00 (2.3011e+00)
Epoch: [8][ 25/125]     Total Loss -3.9037e+00 (-3.8972e+00)    Consistency Loss 7.5170e-01 (7.0395e-01)        Class Cross Entropy 1.5989e+00 (1.5911e+00)     Entropy 2.3013e+00 (2.3007e+00)
Epoch: [8][ 50/125]     Total Loss -3.9573e+00 (-3.9043e+00)    Consistency Loss 6.5426e-01 (7.0276e-01)        Class Cross Entropy 1.5805e+00 (1.5917e+00)     Entropy 2.2988e+00 (2.3007e+00)
Epoch: [8][ 75/125]     Total Loss -4.0695e+00 (-3.9019e+00)    Consistency Loss 6.7736e-01 (7.0409e-01)        Class Cross Entropy 1.5870e+00 (1.5923e+00)     Entropy 2.3011e+00 (2.3007e+00)
Epoch: [8][100/125]     Total Loss -3.8269e+00 (-3.8981e+00)    Consistency Loss 7.5791e-01 (7.0502e-01)        Class Cross Entropy 1.6057e+00 (1.5922e+00)     Entropy 2.3011e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15764880180358887
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3022537231445312, 'consistency': 0.6187893748283386, 'ce': 1.5107207298278809, 'total_loss': -0.17274361848831177}, {'entropy': 2.30224347114563, 'consistency': 0.6189486384391785, 'ce': 1.5107414722442627, 'total_loss': -0.17255336046218872}, {'entropy': 2.302229642868042, 'consistency': 0.6182806491851807, 'ce': 1.5106533765792847, 'total_loss': -0.17329561710357666}], 'lowest_loss_head': 2, 'lowest_loss': -0.17329561710357666}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.842, 'ARI': 0.7014270181128709, 'NMI': 0.7440884827905859, 'ACC Top-5': 0.9772, 'hungarian_match': [(0, 2), (1, 8), (2, 5), (3, 9), (4, 7), (5, 4), (6, 1), (7, 3), (8, 0), (9, 6)]}
New lowest loss on validation set: -0.2054 -> -0.1733
Best ACC on validation set: 0.8419 -> 0.8420
Lowest loss head is 2
Checkpoint ...
Epoch 10/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [9][  0/125]     Total Loss -3.9949e+00 (-3.9949e+00)    Consistency Loss 6.9834e-01 (6.9834e-01)        Class Cross Entropy 1.5833e+00 (1.5833e+00)     Entropy 2.3002e+00 (2.3002e+00)
Epoch: [9][ 25/125]     Total Loss -3.9286e+00 (-3.9302e+00)    Consistency Loss 7.0040e-01 (6.9162e-01)        Class Cross Entropy 1.5943e+00 (1.5878e+00)     Entropy 2.3005e+00 (2.3004e+00)
Epoch: [9][ 50/125]     Total Loss -3.9958e+00 (-3.9223e+00)    Consistency Loss 6.1586e-01 (6.8652e-01)        Class Cross Entropy 1.5720e+00 (1.5876e+00)     Entropy 2.3014e+00 (2.3003e+00)
Epoch: [9][ 75/125]     Total Loss -3.8454e+00 (-3.9116e+00)    Consistency Loss 6.7909e-01 (6.9085e-01)        Class Cross Entropy 1.5928e+00 (1.5893e+00)     Entropy 2.3007e+00 (2.3005e+00)
Epoch: [9][100/125]     Total Loss -3.9668e+00 (-3.9076e+00)    Consistency Loss 7.1721e-01 (6.9330e-01)        Class Cross Entropy 1.5969e+00 (1.5900e+00)     Entropy 2.3018e+00 (2.3005e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15859031677246094
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301494836807251, 'consistency': 0.5900320410728455, 'ce': 1.5063130855560303, 'total_loss': -0.20514971017837524}, {'entropy': 2.3014988899230957, 'consistency': 0.5909677743911743, 'ce': 1.5064616203308105, 'total_loss': -0.20406949520111084}, {'entropy': 2.301536798477173, 'consistency': 0.5928317308425903, 'ce': 1.5067013502120972, 'total_loss': -0.20200371742248535}], 'lowest_loss_head': 0, 'lowest_loss': -0.20514971017837524}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8398, 'ARI': 0.6958872242858496, 'NMI': 0.7422268548847863, 'ACC Top-5': 0.9775, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.1733 -> -0.2051
Lowest loss head is 2
Checkpoint ...
Epoch 11/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [10][  0/125]    Total Loss -3.8885e+00 (-3.8885e+00)    Consistency Loss 6.7387e-01 (6.7387e-01)        Class Cross Entropy 1.5792e+00 (1.5792e+00)     Entropy 2.3007e+00 (2.3007e+00)
Epoch: [10][ 25/125]    Total Loss -3.8953e+00 (-3.8968e+00)    Consistency Loss 7.3205e-01 (6.9997e-01)        Class Cross Entropy 1.5926e+00 (1.5911e+00)     Entropy 2.3002e+00 (2.3007e+00)
Epoch: [10][ 50/125]    Total Loss -3.8648e+00 (-3.8899e+00)    Consistency Loss 7.1688e-01 (6.9937e-01)        Class Cross Entropy 1.5935e+00 (1.5909e+00)     Entropy 2.3010e+00 (2.3006e+00)
Epoch: [10][ 75/125]    Total Loss -3.8433e+00 (-3.8949e+00)    Consistency Loss 7.3284e-01 (7.0388e-01)        Class Cross Entropy 1.6051e+00 (1.5920e+00)     Entropy 2.3020e+00 (2.3006e+00)
Epoch: [10][100/125]    Total Loss -4.0133e+00 (-3.8976e+00)    Consistency Loss 6.8052e-01 (7.0298e-01)        Class Cross Entropy 1.5847e+00 (1.5918e+00)     Entropy 2.3021e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1576542854309082
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301560640335083, 'consistency': 0.5996195673942566, 'ce': 1.5085607767105103, 'total_loss': -0.19338029623031616}, {'entropy': 2.301558494567871, 'consistency': 0.5992707014083862, 'ce': 1.508521556854248, 'total_loss': -0.19376623630523682}, {'entropy': 2.3015551567077637, 'consistency': 0.6005274653434753, 'ce': 1.5087170600891113, 'total_loss': -0.192310631275177}], 'lowest_loss_head': 1, 'lowest_loss': -0.19376623630523682}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8386, 'ARI': 0.6964857840343105, 'NMI': 0.7420746203341718, 'ACC Top-5': 0.9768, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.1733 -> -0.1938
Lowest loss head is 2
Checkpoint ...
Epoch 12/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [11][  0/125]    Total Loss -3.8924e+00 (-3.8924e+00)    Consistency Loss 6.6693e-01 (6.6693e-01)        Class Cross Entropy 1.5822e+00 (1.5822e+00)     Entropy 2.3007e+00 (2.3007e+00)
Epoch: [11][ 25/125]    Total Loss -3.8997e+00 (-3.9192e+00)    Consistency Loss 7.4483e-01 (6.9409e-01)        Class Cross Entropy 1.6072e+00 (1.5904e+00)     Entropy 2.3008e+00 (2.3007e+00)
Epoch: [11][ 50/125]    Total Loss -3.8642e+00 (-3.9103e+00)    Consistency Loss 7.3002e-01 (6.9407e-01)        Class Cross Entropy 1.5959e+00 (1.5901e+00)     Entropy 2.3009e+00 (2.3007e+00)
Epoch: [11][ 75/125]    Total Loss -3.8802e+00 (-3.9119e+00)    Consistency Loss 6.8869e-01 (6.9154e-01)        Class Cross Entropy 1.5875e+00 (1.5890e+00)     Entropy 2.3016e+00 (2.3007e+00)
Epoch: [11][100/125]    Total Loss -3.9387e+00 (-3.9147e+00)    Consistency Loss 6.8131e-01 (6.9115e-01)        Class Cross Entropy 1.5897e+00 (1.5887e+00)     Entropy 2.2997e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.2214043140411377
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3017470836639404, 'consistency': 0.5982176065444946, 'ce': 1.5080277919769287, 'total_loss': -0.1955016851425171}, {'entropy': 2.3017489910125732, 'consistency': 0.599717915058136, 'ce': 1.5082824230194092, 'total_loss': -0.19374865293502808}, {'entropy': 2.301732301712036, 'consistency': 0.5989665389060974, 'ce': 1.5081695318222046, 'total_loss': -0.19459623098373413}], 'lowest_loss_head': 0, 'lowest_loss': -0.1955016851425171}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8358, 'ARI': 0.6911516447491679, 'NMI': 0.7371048757222854, 'ACC Top-5': 0.9754, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.1733 -> -0.1955
Lowest loss head is 2
Checkpoint ...
Epoch 13/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [12][  0/125]    Total Loss -3.8870e+00 (-3.8870e+00)    Consistency Loss 7.3413e-01 (7.3413e-01)        Class Cross Entropy 1.6042e+00 (1.6042e+00)     Entropy 2.3008e+00 (2.3008e+00)
Epoch: [12][ 25/125]    Total Loss -3.8734e+00 (-3.9153e+00)    Consistency Loss 7.0915e-01 (6.9136e-01)        Class Cross Entropy 1.5895e+00 (1.5887e+00)     Entropy 2.3018e+00 (2.3006e+00)
Epoch: [12][ 50/125]    Total Loss -3.9399e+00 (-3.9047e+00)    Consistency Loss 7.0694e-01 (6.9561e-01)        Class Cross Entropy 1.5938e+00 (1.5902e+00)     Entropy 2.3016e+00 (2.3005e+00)
Epoch: [12][ 75/125]    Total Loss -3.9025e+00 (-3.9092e+00)    Consistency Loss 6.7915e-01 (6.9560e-01)        Class Cross Entropy 1.5859e+00 (1.5903e+00)     Entropy 2.3004e+00 (2.3005e+00)
Epoch: [12][100/125]    Total Loss -4.0029e+00 (-3.9082e+00)    Consistency Loss 6.5077e-01 (6.9483e-01)        Class Cross Entropy 1.5694e+00 (1.5897e+00)     Entropy 2.3011e+00 (2.3005e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.16126585006713867
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.302121639251709, 'consistency': 0.6049908399581909, 'ce': 1.5082783699035645, 'total_loss': -0.1888524293899536}, {'entropy': 2.3021442890167236, 'consistency': 0.6038639545440674, 'ce': 1.5081452131271362, 'total_loss': -0.19013512134552002}, {'entropy': 2.302112579345703, 'consistency': 0.6054181456565857, 'ce': 1.5083773136138916, 'total_loss': -0.18831712007522583}], 'lowest_loss_head': 1, 'lowest_loss': -0.19013512134552002}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8445, 'ARI': 0.7066823212354436, 'NMI': 0.7463347017011431, 'ACC Top-5': 0.9781, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
New lowest loss on validation set: -0.1733 -> -0.1901
Best ACC on validation set: 0.8420 -> 0.8445
Lowest loss head is 1
Checkpoint ...
Epoch 14/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [13][  0/125]    Total Loss -3.8866e+00 (-3.8866e+00)    Consistency Loss 6.8746e-01 (6.8746e-01)        Class Cross Entropy 1.5877e+00 (1.5877e+00)     Entropy 2.3004e+00 (2.3004e+00)
Epoch: [13][ 25/125]    Total Loss -3.8579e+00 (-3.9151e+00)    Consistency Loss 6.8105e-01 (6.8236e-01)        Class Cross Entropy 1.5840e+00 (1.5865e+00)     Entropy 2.3007e+00 (2.3006e+00)
Epoch: [13][ 50/125]    Total Loss -3.9764e+00 (-3.9207e+00)    Consistency Loss 6.8717e-01 (6.8646e-01)        Class Cross Entropy 1.5878e+00 (1.5879e+00)     Entropy 2.3011e+00 (2.3006e+00)
Epoch: [13][ 75/125]    Total Loss -3.8555e+00 (-3.9225e+00)    Consistency Loss 6.6292e-01 (6.8502e-01)        Class Cross Entropy 1.5824e+00 (1.5876e+00)     Entropy 2.3015e+00 (2.3007e+00)
Epoch: [13][100/125]    Total Loss -4.0169e+00 (-3.9248e+00)    Consistency Loss 6.6807e-01 (6.8585e-01)        Class Cross Entropy 1.5812e+00 (1.5877e+00)     Entropy 2.2987e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1590123176574707
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301485300064087, 'consistency': 0.5880923867225647, 'ce': 1.5067923069000244, 'total_loss': -0.2066006064414978}, {'entropy': 2.3014872074127197, 'consistency': 0.5883548259735107, 'ce': 1.5068433284759521, 'total_loss': -0.20628905296325684}, {'entropy': 2.3014683723449707, 'consistency': 0.5885593891143799, 'ce': 1.5068647861480713, 'total_loss': -0.20604419708251953}], 'lowest_loss_head': 0, 'lowest_loss': -0.2066006064414978}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8406, 'ARI': 0.7020892341097339, 'NMI': 0.7438387454549923, 'ACC Top-5': 0.9774, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.1901 -> -0.2066
Lowest loss head is 1
Checkpoint ...
Epoch 15/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [14][  0/125]    Total Loss -3.8915e+00 (-3.8915e+00)    Consistency Loss 6.4634e-01 (6.4634e-01)        Class Cross Entropy 1.5744e+00 (1.5744e+00)     Entropy 2.3009e+00 (2.3009e+00)
Epoch: [14][ 25/125]    Total Loss -3.9482e+00 (-3.9098e+00)    Consistency Loss 7.0232e-01 (6.9025e-01)        Class Cross Entropy 1.5927e+00 (1.5876e+00)     Entropy 2.3021e+00 (2.3008e+00)
Epoch: [14][ 50/125]    Total Loss -3.9070e+00 (-3.9042e+00)    Consistency Loss 7.2550e-01 (6.9936e-01)        Class Cross Entropy 1.5929e+00 (1.5894e+00)     Entropy 2.2993e+00 (2.3007e+00)
Epoch: [14][ 75/125]    Total Loss -3.9736e+00 (-3.9044e+00)    Consistency Loss 6.8473e-01 (6.9684e-01)        Class Cross Entropy 1.5882e+00 (1.5888e+00)     Entropy 2.3012e+00 (2.3008e+00)
Epoch: [14][100/125]    Total Loss -3.9337e+00 (-3.9092e+00)    Consistency Loss 7.0114e-01 (6.9823e-01)        Class Cross Entropy 1.5888e+00 (1.5892e+00)     Entropy 2.3008e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15612196922302246
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3014819622039795, 'consistency': 0.5959929823875427, 'ce': 1.5082552433013916, 'total_loss': -0.19723373651504517}, {'entropy': 2.3014538288116455, 'consistency': 0.594898521900177, 'ce': 1.5081318616867065, 'total_loss': -0.19842344522476196}, {'entropy': 2.301427125930786, 'consistency': 0.5965140461921692, 'ce': 1.5083515644073486, 'total_loss': -0.1965615153312683}], 'lowest_loss_head': 1, 'lowest_loss': -0.19842344522476196}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8397, 'ARI': 0.7003188567983248, 'NMI': 0.7427392167345475, 'ACC Top-5': 0.9796, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.1901 -> -0.1984
Lowest loss head is 1
Checkpoint ...
Epoch 16/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [15][  0/125]    Total Loss -3.9069e+00 (-3.9069e+00)    Consistency Loss 6.6601e-01 (6.6601e-01)        Class Cross Entropy 1.5826e+00 (1.5826e+00)     Entropy 2.3010e+00 (2.3010e+00)
Epoch: [15][ 25/125]    Total Loss -3.9073e+00 (-3.8908e+00)    Consistency Loss 6.9950e-01 (7.0107e-01)        Class Cross Entropy 1.5958e+00 (1.5915e+00)     Entropy 2.3005e+00 (2.3008e+00)
Epoch: [15][ 50/125]    Total Loss -3.9098e+00 (-3.8992e+00)    Consistency Loss 7.0592e-01 (6.9708e-01)        Class Cross Entropy 1.5927e+00 (1.5908e+00)     Entropy 2.3005e+00 (2.3008e+00)
Epoch: [15][ 75/125]    Total Loss -3.7658e+00 (-3.9037e+00)    Consistency Loss 7.1401e-01 (6.9240e-01)        Class Cross Entropy 1.5882e+00 (1.5896e+00)     Entropy 2.3000e+00 (2.3007e+00)
Epoch: [15][100/125]    Total Loss -4.0608e+00 (-3.9092e+00)    Consistency Loss 6.7645e-01 (6.8959e-01)        Class Cross Entropy 1.5875e+00 (1.5891e+00)     Entropy 2.3011e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15662193298339844
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3015501499176025, 'consistency': 0.5983465313911438, 'ce': 1.5075660943984985, 'total_loss': -0.1956375241279602}, {'entropy': 2.3015451431274414, 'consistency': 0.5994644165039062, 'ce': 1.5077685117721558, 'total_loss': -0.1943122148513794}, {'entropy': 2.301490545272827, 'consistency': 0.5997306108474731, 'ce': 1.5078051090240479, 'total_loss': -0.19395482540130615}], 'lowest_loss_head': 0, 'lowest_loss': -0.1956375241279602}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8397, 'ARI': 0.6979625988232296, 'NMI': 0.7392669472929864, 'ACC Top-5': 0.9725, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.1901 -> -0.1956
Lowest loss head is 1
Checkpoint ...
Epoch 17/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [16][  0/125]    Total Loss -3.9387e+00 (-3.9387e+00)    Consistency Loss 7.0455e-01 (7.0455e-01)        Class Cross Entropy 1.5903e+00 (1.5903e+00)     Entropy 2.3013e+00 (2.3013e+00)
Epoch: [16][ 25/125]    Total Loss -4.0782e+00 (-3.9107e+00)    Consistency Loss 6.8162e-01 (6.7943e-01)        Class Cross Entropy 1.5879e+00 (1.5860e+00)     Entropy 2.3002e+00 (2.3010e+00)
Epoch: [16][ 50/125]    Total Loss -3.8732e+00 (-3.9041e+00)    Consistency Loss 6.7175e-01 (6.8839e-01)        Class Cross Entropy 1.5821e+00 (1.5877e+00)     Entropy 2.3006e+00 (2.3010e+00)
Epoch: [16][ 75/125]    Total Loss -3.9070e+00 (-3.9073e+00)    Consistency Loss 6.8591e-01 (6.8666e-01)        Class Cross Entropy 1.5879e+00 (1.5872e+00)     Entropy 2.3013e+00 (2.3008e+00)
Epoch: [16][100/125]    Total Loss -3.7925e+00 (-3.9090e+00)    Consistency Loss 7.1431e-01 (6.8734e-01)        Class Cross Entropy 1.6023e+00 (1.5876e+00)     Entropy 2.2999e+00 (2.3007e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.15733790397644043
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3009934425354004, 'consistency': 0.5941406488418579, 'ce': 1.5075174570083618, 'total_loss': -0.19933533668518066}, {'entropy': 2.3009979724884033, 'consistency': 0.5934723019599915, 'ce': 1.5074431896209717, 'total_loss': -0.20008248090744019}, {'entropy': 2.3009707927703857, 'consistency': 0.5942391753196716, 'ce': 1.5075621604919434, 'total_loss': -0.19916945695877075}], 'lowest_loss_head': 1, 'lowest_loss': -0.20008248090744019}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8433, 'ARI': 0.7046400584906486, 'NMI': 0.7491107225514637, 'ACC Top-5': 0.981, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.1901 -> -0.2001
Lowest loss head is 1
Checkpoint ...
Epoch 18/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [17][  0/125]    Total Loss -3.8876e+00 (-3.8876e+00)    Consistency Loss 6.7223e-01 (6.7223e-01)        Class Cross Entropy 1.5819e+00 (1.5819e+00)     Entropy 2.3004e+00 (2.3004e+00)
Epoch: [17][ 25/125]    Total Loss -3.8103e+00 (-3.9249e+00)    Consistency Loss 7.2739e-01 (6.7011e-01)        Class Cross Entropy 1.6031e+00 (1.5834e+00)     Entropy 2.3006e+00 (2.3008e+00)
Epoch: [17][ 50/125]    Total Loss -3.9327e+00 (-3.9350e+00)    Consistency Loss 6.9284e-01 (6.7116e-01)        Class Cross Entropy 1.5938e+00 (1.5843e+00)     Entropy 2.2999e+00 (2.3007e+00)
Epoch: [17][ 75/125]    Total Loss -3.8564e+00 (-3.9284e+00)    Consistency Loss 6.6861e-01 (6.7467e-01)        Class Cross Entropy 1.5869e+00 (1.5850e+00)     Entropy 2.3002e+00 (2.3008e+00)
Epoch: [17][100/125]    Total Loss -3.9165e+00 (-3.9234e+00)    Consistency Loss 6.6477e-01 (6.7609e-01)        Class Cross Entropy 1.5747e+00 (1.5856e+00)     Entropy 2.3007e+00 (2.3008e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.1530764102935791
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.301055669784546, 'consistency': 0.6037461161613464, 'ce': 1.5093183517456055, 'total_loss': -0.187991201877594}, {'entropy': 2.3010668754577637, 'consistency': 0.6053434610366821, 'ce': 1.5095689296722412, 'total_loss': -0.18615448474884033}, {'entropy': 2.301039695739746, 'consistency': 0.6054309606552124, 'ce': 1.5095789432525635, 'total_loss': -0.18602979183197021}], 'lowest_loss_head': 0, 'lowest_loss': -0.187991201877594}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8414, 'ARI': 0.7028560560673609, 'NMI': 0.7443062998124685, 'ACC Top-5': 0.9753, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.1901 -> -0.1880
Lowest loss head is 1
Checkpoint ...
Epoch 19/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [18][  0/125]    Total Loss -3.9658e+00 (-3.9658e+00)    Consistency Loss 7.0512e-01 (7.0512e-01)        Class Cross Entropy 1.5937e+00 (1.5937e+00)     Entropy 2.2986e+00 (2.2986e+00)
Epoch: [18][ 25/125]    Total Loss -3.8576e+00 (-3.9081e+00)    Consistency Loss 6.6142e-01 (6.8867e-01)        Class Cross Entropy 1.5824e+00 (1.5881e+00)     Entropy 2.2988e+00 (2.3005e+00)
Epoch: [18][ 50/125]    Total Loss -3.9125e+00 (-3.9042e+00)    Consistency Loss 6.9692e-01 (6.8966e-01)        Class Cross Entropy 1.5924e+00 (1.5881e+00)     Entropy 2.2996e+00 (2.3006e+00)
Epoch: [18][ 75/125]    Total Loss -3.8597e+00 (-3.9102e+00)    Consistency Loss 7.3141e-01 (6.8666e-01)        Class Cross Entropy 1.5999e+00 (1.5877e+00)     Entropy 2.3004e+00 (2.3006e+00)
Epoch: [18][100/125]    Total Loss -3.9356e+00 (-3.9171e+00)    Consistency Loss 6.9466e-01 (6.8337e-01)        Class Cross Entropy 1.5901e+00 (1.5869e+00)     Entropy 2.3012e+00 (2.3006e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.18852615356445312
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3017520904541016, 'consistency': 0.5997055768966675, 'ce': 1.5076930522918701, 'total_loss': -0.19435346126556396}, {'entropy': 2.301743984222412, 'consistency': 0.5980228781700134, 'ce': 1.5075079202651978, 'total_loss': -0.19621318578720093}, {'entropy': 2.30171275138855, 'consistency': 0.5999130606651306, 'ce': 1.5077418088912964, 'total_loss': -0.1940578818321228}], 'lowest_loss_head': 1, 'lowest_loss': -0.19621318578720093}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.8362, 'ARI': 0.6951203719459241, 'NMI': 0.7377172223040563, 'ACC Top-5': 0.9762, 'hungarian_match': [(0, 3), (1, 7), (2, 0), (3, 9), (4, 4), (5, 5), (6, 2), (7, 1), (8, 8), (9, 6)]}
No new lowest loss on validation set: -0.1901 -> -0.1962
Lowest loss head is 1
Checkpoint ...
Epoch 20/20
---------------
Adjusted learning rate to 0.00010
Train ...
Epoch: [19][  0/125]    Total Loss -3.9623e+00 (-3.9623e+00)    Consistency Loss 6.5281e-01 (6.5281e-01)        Class Cross Entropy 1.5781e+00 (1.5781e+00)     Entropy 2.3017e+00 (2.3017e+00)
Epoch: [19][ 25/125]    Total Loss -3.8820e+00 (-3.9091e+00)    Consistency Loss 6.8408e-01 (6.8125e-01)        Class Cross Entropy 1.5906e+00 (1.5865e+00)     Entropy 2.3012e+00 (2.3007e+00)
Epoch: [19][ 50/125]    Total Loss -4.0362e+00 (-3.9073e+00)    Consistency Loss 6.6814e-01 (6.8648e-01)        Class Cross Entropy 1.5720e+00 (1.5878e+00)     Entropy 2.3001e+00 (2.3005e+00)
Epoch: [19][ 75/125]    Total Loss -3.9205e+00 (-3.9084e+00)    Consistency Loss 6.5564e-01 (6.8544e-01)        Class Cross Entropy 1.5757e+00 (1.5871e+00)     Entropy 2.3009e+00 (2.3006e+00)
Epoch: [19][100/125]    Total Loss -3.9769e+00 (-3.9103e+00)    Consistency Loss 6.5892e-01 (6.8736e-01)        Class Cross Entropy 1.5741e+00 (1.5873e+00)     Entropy 2.3001e+00 (2.3005e+00)
Obtain prediction on train set ...
Execute nn_serach ...
the elpased time is  0.21495366096496582
Make prediction on validation set ...
Evaluate based on SCAN loss ...
{'scan': [{'entropy': 2.3017170429229736, 'consistency': 0.6060104370117188, 'ce': 1.509312629699707, 'total_loss': -0.18639397621154785}, {'entropy': 2.3017077445983887, 'consistency': 0.6080479025840759, 'ce': 1.5096189975738525, 'total_loss': -0.1840408444404602}, {'entropy': 2.3016867637634277, 'consistency': 0.6068230271339417, 'ce': 1.5094218254089355, 'total_loss': -0.18544191122055054}], 'lowest_loss_head': 0, 'lowest_loss': -0.18639397621154785}
Evaluate with hungarian matching algorithm ...
{'ACC': 0.842, 'ARI': 0.7030062621428896, 'NMI': 0.7439707863558747, 'ACC Top-5': 0.9765, 'hungarian_match': [(0, 2), (1, 0), (2, 5), (3, 3), (4, 4), (5, 7), (6, 1), (7, 8), (8, 9), (9, 6)]}
No new lowest loss on validation set: -0.1901 -> -0.1864
Lowest loss head is 1
Checkpoint ...
Evaluate best model based on SCAN metric at the end
[0.8406, 0.8389, 0.8368, 0.8394, 0.8369, 0.8402, 0.8385, 0.8419, 0.842, 0.8398, 0.8386, 0.8358, 0.8445, 0.8406, 0.8397, 0.8397, 0.8433, 0.8414, 0.8362, 0.842]
[-0.21078038215637207, -0.1714436411857605, -0.2096913456916809, -0.1833701729774475, -0.19557976722717285, -0.2159246802330017, -0.18447482585906982, -0.2053762674331665, -0.17329561710357666, -0.20514971017837524, -0.19376623630523682, -0.1955016851425171, -0.19013512134552002, -0.2066006064414978, -0.19842344522476196, -0.1956375241279602, -0.20008248090744019, -0.187991201877594, -0.19621318578720093, -0.18639397621154785]